#!/usr/bin/env python3
"""
Áõ¥Êé•ÈÄöËøá SQL ÊèíÂÖ•ÊµãËØïÊï∞ÊçÆ

Áî®Ê≥ïÔºö
    # ÁîüÊàêÂ∏∏ËßÑÊµãËØïÊï∞ÊçÆ
    python backend/scripts/generate_test_data_sql.py
    python backend/scripts/generate_test_data_sql.py --clear  # Ê∏ÖÈô§ÂêéÈáçÊñ∞ÁîüÊàê
    
    # ÁîüÊàêÁôæ‰∏áÁ∫ßÊµãËØïÊï∞ÊçÆ(Áî®‰∫éÊµãËØï Dashboard Âç°ÁâáÊ∫¢Âá∫)
    python backend/scripts/generate_test_data_sql.py --million
    python backend/scripts/generate_test_data_sql.py --million --clear  # Ê∏ÖÈô§ÂêéÁîüÊàêÁôæ‰∏áÁ∫ßÊï∞ÊçÆ
    
Áôæ‰∏áÁ∫ßÊï∞ÊçÆËØ¥ÊòéÔºö
    - ÁõÆÊ†á: 1,000
    - Â≠êÂüüÂêç: 200,000
    - ÁΩëÁ´ô: 200,000
    - Á´ØÁÇπ: 200,000
    - IP (host_port_mapping): 200,000
    - ÊºèÊ¥û: 200,000 (critical: 50k, high: 50k, medium: 50k, low: 30k, info: 20k)
    - ÊÄªËµÑ‰∫ß: ~660,000
"""

import argparse
import random
import json
import os
from datetime import datetime, timedelta
from decimal import Decimal
from pathlib import Path

import psycopg2
from psycopg2.extras import execute_values


def load_env_file(env_path: str) -> dict:
    """‰ªé .env Êñá‰ª∂Âä†ËΩΩÁéØÂ¢ÉÂèòÈáè"""
    env_vars = {}
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    return env_vars


def get_db_config() -> dict:
    """‰ªé docker/.env ËØªÂèñÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ"""
    # Ëé∑ÂèñÈ°πÁõÆÊ†πÁõÆÂΩï
    script_dir = Path(__file__).resolve().parent
    project_root = script_dir.parent.parent
    env_path = project_root / 'docker' / '.env'
    
    env_vars = load_env_file(str(env_path))
    
    # Ëé∑ÂèñÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºådocker/.env ‰∏≠ DB_HOST=postgres ÊòØÂÆπÂô®ÂÜÖÂú∞ÂùÄÔºåÊú¨Âú∞ËøêË°åÈúÄË¶ÅÁî® localhost
    db_host = env_vars.get('DB_HOST', 'postgres')
    if db_host == 'postgres':
        db_host = 'localhost'  # Êú¨Âú∞ËøêË°åËÑöÊú¨Êó∂‰ΩøÁî® localhost
    
    return {
        'host': db_host,
        'port': int(env_vars.get('DB_PORT', 5432)),
        'dbname': env_vars.get('DB_NAME', 'xingrin'),
        'user': env_vars.get('DB_USER', 'postgres'),
        'password': env_vars.get('DB_PASSWORD', ''),
    }


DB_CONFIG = get_db_config()


class TestDataGenerator:
    def __init__(self, clear: bool = False):
        self.conn = psycopg2.connect(**DB_CONFIG)
        self.conn.autocommit = False
        self.clear = clear
        
    def run(self):
        try:
            if self.clear:
                print("üóëÔ∏è  Ê∏ÖÈô§Áé∞ÊúâÊï∞ÊçÆ...")
                self.clear_data()
                
            print("üöÄ ÂºÄÂßãÁîüÊàêÊµãËØïÊï∞ÊçÆ...\n")
            
            engine_ids = self.create_engines()
            worker_ids = self.create_workers()
            org_ids = self.create_organizations()
            target_ids = self.create_targets(org_ids)
            scan_ids = self.create_scans(target_ids, engine_ids, worker_ids)
            self.create_scheduled_scans(org_ids, target_ids, engine_ids)
            self.create_subdomains(target_ids)
            website_ids = self.create_websites(target_ids)
            self.create_endpoints(target_ids)
            self.create_directories(target_ids, website_ids)
            self.create_host_port_mappings(target_ids)
            self.create_vulnerabilities(target_ids)
            
            # ÁîüÊàêÂø´ÁÖßÊï∞ÊçÆ(Êâ´ÊèèÂéÜÂè≤ËØ¶ÁªÜÈ°µÈù¢‰ΩøÁî®)
            self.create_subdomain_snapshots(scan_ids)
            self.create_website_snapshots(scan_ids)
            self.create_endpoint_snapshots(scan_ids)
            self.create_directory_snapshots(scan_ids)
            self.create_host_port_mapping_snapshots(scan_ids)
            self.create_vulnerability_snapshots(scan_ids)
            
            self.conn.commit()
            print("\n‚úÖ ÊµãËØïÊï∞ÊçÆÁîüÊàêÂÆåÊàêÔºÅ")
        except Exception as e:
            self.conn.rollback()
            print(f"\n‚ùå ÁîüÊàêÂ§±Ë¥•: {e}")
            raise
        finally:
            self.conn.close()

    def clear_data(self):
        """Ê∏ÖÈô§ÊâÄÊúâÊµãËØïÊï∞ÊçÆ"""
        cur = self.conn.cursor()
        tables = [
            # Âø´ÁÖßË°®(ÂÖàÂà†Èô§ÔºåÂõ†‰∏∫ÊúâÂ§ñÈîÆ‰æùËµñ scan)
            'vulnerability_snapshot', 'host_port_mapping_snapshot', 'directory_snapshot',
            'endpoint_snapshot', 'website_snapshot', 'subdomain_snapshot',
            # ËµÑ‰∫ßË°®
            'vulnerability', 'host_port_mapping', 'directory', 'endpoint',
            'website', 'subdomain', 'scheduled_scan', 'scan',
            'organization_targets', 'target', 'organization',
            'nuclei_template_repo', 'wordlist', 'scan_engine', 'worker_node'
        ]
        for table in tables:
            cur.execute(f"DELETE FROM {table}")
        self.conn.commit()
        print("  ‚úì Êï∞ÊçÆÊ∏ÖÈô§ÂÆåÊàê\n")

    def create_workers(self) -> list:
        """ÂàõÂª∫ Worker ËäÇÁÇπ"""
        print("üë∑ ÂàõÂª∫ Worker ËäÇÁÇπ...")
        cur = self.conn.cursor()
        
        # ÁîüÊàêÈöèÊú∫ÂêéÁºÄÁ°Æ‰øùÂîØ‰∏ÄÊÄß
        suffix = random.randint(1000, 9999)
        
        regions = ['asia-singapore-1', 'asia-singapore-2', 'asia-tokyo-1', 'asia-tokyo-2', 'asia-hongkong-1', 
                   'asia-mumbai-1', 'asia-seoul-1', 'asia-sydney-1', 'asia-jakarta-1', 'asia-osaka-1',
                   'europe-frankfurt-1', 'europe-frankfurt-2', 'europe-london-1', 'europe-london-2', 
                   'europe-paris-1', 'europe-ireland-1', 'europe-stockholm-1', 'europe-milan-1',
                   'us-east-virginia-1', 'us-east-virginia-2', 'us-east-ohio-1', 'us-west-oregon-1', 
                   'us-west-oregon-2', 'us-west-california-1', 'us-central-iowa-1',
                   'australia-sydney-1', 'australia-melbourne-1', 'brazil-saopaulo-1', 
                   'canada-montreal-1', 'southafrica-capetown-1', 'middleeast-bahrain-1']
        statuses = ['online', 'offline', 'pending', 'deploying', 'maintenance', 'error', 'upgrading']
        
        workers = [
            (f'local-worker-primary-high-performance-{suffix}', '127.0.0.1', True, 'online'),
            (f'local-worker-secondary-backup-{suffix}', '127.0.0.2', True, 'online'),
        ]
        
        # ÈöèÊú∫ÁîüÊàê 30-50 ‰∏™ËøúÁ®ã worker
        num_remote = random.randint(30, 50)
        selected_regions = random.sample(regions, min(num_remote, len(regions)))
        for i, region in enumerate(selected_regions):
            ip = f'192.168.{random.randint(1, 254)}.{random.randint(1, 254)}'
            status = random.choice(statuses)
            workers.append((f'remote-worker-{region}-{suffix}-{i:02d}', ip, False, status))
        
        ids = []
        for name, ip, is_local, status in workers:
            cur.execute("""
                INSERT INTO worker_node (name, ip_address, ssh_port, username, password, is_local, status, created_at, updated_at)
                VALUES (%s, %s, 22, 'root', '', %s, %s, NOW(), NOW())
                ON CONFLICT (name) DO UPDATE SET updated_at = NOW()
                RETURNING id
            """, (name, ip, is_local, status))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™ Worker ËäÇÁÇπ\n")
        return ids

    def create_engines(self) -> list:
        """ÂàõÂª∫Êâ´ÊèèÂºïÊìé"""
        print("‚öôÔ∏è  ÂàõÂª∫Êâ´ÊèèÂºïÊìé...")
        cur = self.conn.cursor()
        
        suffix = random.randint(1000, 9999)
        
        engine_templates = [
            ('Full-Comprehensive-Security-Assessment-Enterprise-Grade-Vulnerability-Detection-System', 'subdomain_discovery:\n  enabled: true\n  tools: [subfinder, amass, findomain, assetfinder, chaos]\n  timeout: {timeout}\n  resolvers: [8.8.8.8, 1.1.1.1, 9.9.9.9]\nvulnerability_scanning:\n  enabled: true\n  nuclei:\n    severity: critical,high,medium,low,info\n    rate_limit: {rate}\n    concurrency: {conc}\n    templates: [cves, vulnerabilities, exposures, misconfigurations, default-logins]'),
            ('Quick-Reconnaissance-Fast-Discovery-Lightweight-Asset-Enumeration', 'subdomain_discovery:\n  enabled: true\n  tools: [subfinder, assetfinder]\n  timeout: {timeout}\n  passive_only: true\nport_scanning:\n  enabled: true\n  top_ports: {ports}\n  rate: {rate}'),
            ('Deep-Vulnerability-Assessment-Extended-Security-Analysis-Framework', 'vulnerability_scanning:\n  enabled: true\n  nuclei:\n    severity: critical,high,medium,low,info\n    templates: [cves, vulnerabilities, exposures, misconfigurations, default-logins, takeovers]\n    rate_limit: {rate}\n    concurrency: {conc}\n  dalfox:\n    enabled: true\n    blind_xss: true\n  sqlmap:\n    enabled: true\n    level: 3\n    risk: 2'),
            ('Passive-Information-Gathering-OSINT-Intelligence-Collection-Platform', 'subdomain_discovery:\n  enabled: true\n  passive_only: true\n  sources: [crtsh, hackertarget, threatcrowd, virustotal, securitytrails, shodan, censys, binaryedge]\n  timeout: {timeout}\n  dns_bruteforce: false'),
            ('Web-Application-Security-Scanner-OWASP-Compliance-Testing-Suite', 'web_discovery:\n  enabled: true\n  httpx:\n    threads: {conc}\n    follow_redirects: true\n    screenshot: true\nvulnerability_scanning:\n  enabled: true\n  dalfox:\n    enabled: true\n    blind_xss: true\n  nuclei:\n    templates: [cves, vulnerabilities, exposures]'),
            ('API-Endpoint-Security-Audit-RESTful-GraphQL-Assessment-Tool', 'endpoint_discovery:\n  enabled: true\n  katana:\n    depth: {depth}\n    concurrency: {conc}\n    js_crawl: true\n    automatic_form_fill: true\nvulnerability_scanning:\n  enabled: true\n  nuclei:\n    templates: [exposures, misconfigurations]'),
            ('Infrastructure-Port-Scanner-Network-Service-Detection-Engine', 'port_scanning:\n  enabled: true\n  naabu:\n    top_ports: {ports}\n    rate: {rate}\n    scan_all_ips: true\n  service_detection: true\n  version_detection: true\n  os_detection: true'),
            ('Directory-Bruteforce-Engine-Content-Discovery-Fuzzing-Platform', 'directory_bruteforce:\n  enabled: true\n  ffuf:\n    threads: {conc}\n    wordlist: [common.txt, raft-large-directories.txt, raft-large-files.txt]\n    recursion_depth: {depth}\n    extensions: [php, asp, aspx, jsp, html, js, json, xml]'),
            ('Cloud-Infrastructure-Security-Assessment-AWS-Azure-GCP-Scanner', 'cloud_scanning:\n  enabled: true\n  providers: [aws, azure, gcp]\n  services: [s3, ec2, rds, lambda, storage, compute, sql]\n  misconfigurations: true\n  public_exposure: true'),
            ('Container-Security-Scanner-Kubernetes-Docker-Vulnerability-Detector', 'container_scanning:\n  enabled: true\n  kubernetes:\n    enabled: true\n    rbac_audit: true\n    network_policies: true\n  docker:\n    enabled: true\n    image_scanning: true\n    dockerfile_lint: true'),
            ('Mobile-Application-Security-Testing-iOS-Android-Assessment-Framework', 'mobile_scanning:\n  enabled: true\n  platforms: [ios, android]\n  static_analysis: true\n  dynamic_analysis: true\n  api_testing: true\n  ssl_pinning_bypass: true'),
            ('Compliance-Audit-Scanner-PCI-DSS-HIPAA-SOC2-Assessment-Tool', 'compliance_scanning:\n  enabled: true\n  frameworks: [pci-dss, hipaa, soc2, gdpr, iso27001]\n  automated_reporting: true\n  evidence_collection: true'),
        ]
        
        # ÈöèÊú∫ÈÄâÊã© 8-12 ‰∏™ÂºïÊìéÊ®°Êùø
        num_engines = random.randint(8, 12)
        selected = random.sample(engine_templates, min(num_engines, len(engine_templates)))
        
        ids = []
        for name_base, config_template in selected:
            name = f'{name_base}-{suffix}'
            config = config_template.format(
                rate=random.choice([100, 150, 200, 300]),
                conc=random.choice([10, 20, 50, 100]),
                timeout=random.choice([300, 600, 900, 1200]),
                ports=random.choice([100, 1000, 'full']),
                depth=random.choice([2, 3, 4, 5])
            )
            cur.execute("""
                INSERT INTO scan_engine (name, configuration, created_at, updated_at)
                VALUES (%s, %s, NOW(), NOW())
                ON CONFLICT (name) DO UPDATE SET configuration = EXCLUDED.configuration, updated_at = NOW()
                RETURNING id
            """, (name, config))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™Êâ´ÊèèÂºïÊìé\n")
        return ids

    def create_organizations(self) -> list:
        """ÂàõÂª∫ÁªÑÁªá"""
        print("üè¢ ÂàõÂª∫ÁªÑÁªá...")
        cur = self.conn.cursor()
        
        suffix = random.randint(1000, 9999)
        
        org_templates = [
            ('Acme Corporation', 'ÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÊäÄÊúØËß£ÂÜ≥ÊñπÊ°àÊèê‰æõÂïÜÔºå‰∏ìÊ≥®‰∫é‰ºÅ‰∏öÁ∫ßËΩØ‰ª∂ÂºÄÂèë„ÄÅ‰∫ëËÆ°ÁÆóÊúçÂä°ÂíåÁΩëÁªúÂÆâÂÖ®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÂÖ¨Âè∏ÊàêÁ´ã‰∫é1995Âπ¥ÔºåÊÄªÈÉ®‰Ωç‰∫éÁ°ÖË∞∑ÔºåÂú®ÂÖ®ÁêÉ50Â§ö‰∏™ÂõΩÂÆ∂ËÆæÊúâÂàÜÊîØÊú∫ÊûÑÔºåÂëòÂ∑•Ë∂ÖËøá10‰∏á‰∫∫ÔºåÂπ¥Ëê•Êî∂Ë∂ÖËøá500‰∫øÁæéÂÖÉ„ÄÇ'),
            ('TechStart Innovation Labs', '‰∏ìÊ≥®‰∫é‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÊú∫Âô®Â≠¶‰π†ÂíåÂå∫ÂùóÈìæÊäÄÊúØÁ†îÂèëÁöÑÂàõÊñ∞ÂÆûÈ™åÂÆ§„ÄÇÊã•ÊúâË∂ÖËøá200ÂêçÂçöÂ£´Á∫ßÁ†îÁ©∂‰∫∫ÂëòÔºå‰∏éÂÖ®ÁêÉÈ°∂Â∞ñÂ§ßÂ≠¶Âª∫Á´ã‰∫ÜÊ∑±Â∫¶Âêà‰ΩúÂÖ≥Á≥ªÔºåÂ∑≤Ëé∑ÂæóË∂ÖËøá500È°πÊäÄÊúØ‰∏ìÂà©„ÄÇ'),
            ('Global Financial Services', 'Êèê‰æõÂÖ®Êñπ‰ΩçÊï∞Â≠óÈì∂Ë°åÊúçÂä°ÁöÑÈáëËûçÁßëÊäÄÂÖ¨Âè∏ÔºåÂåÖÊã¨ÁßªÂä®ÊîØ‰ªò„ÄÅÂú®Á∫øË¥∑Ê¨æ„ÄÅÊäïËµÑÁêÜË¥¢Á≠âÊúçÂä°„ÄÇÊúçÂä°Ë¶ÜÁõñÂÖ®ÁêÉ180‰∏™ÂõΩÂÆ∂ÂíåÂú∞Âå∫ÔºåÊ≥®ÂÜåÁî®Êà∑Ë∂ÖËøá5‰∫øÔºåÊó•Âùá‰∫§ÊòìÈ¢ùË∂ÖËøá100‰∫øÁæéÂÖÉ„ÄÇ'),
            ('HealthCare Plus Medical', 'ÂåªÁñó‰ø°ÊÅØÂåñËß£ÂÜ≥ÊñπÊ°àÊèê‰æõÂïÜÔºå‰∏ìÊ≥®‰∫éÁîµÂ≠êÁóÖÂéÜÁ≥ªÁªü„ÄÅÂåªÈô¢‰ø°ÊÅØÁÆ°ÁêÜÁ≥ªÁªüÂíåËøúÁ®ãÂåªÁñóÂπ≥Âè∞ÂºÄÂèë„ÄÇ‰∫ßÂìÅÂ∑≤ÈÉ®ÁΩ≤Âú®ÂÖ®ÁêÉ3000Â§öÂÆ∂ÂåªÁñóÊú∫ÊûÑÔºåÊúçÂä°Ë∂ÖËøá1‰∫øÊÇ£ËÄÖ„ÄÇ'),
            ('E-Commerce Mega Platform', '‰∫öÂ§™Âú∞Âå∫ÊúÄÂ§ßÁöÑÁîµÂ≠êÂïÜÂä°Âπ≥Âè∞‰πã‰∏ÄÔºåÊèê‰æõ B2B„ÄÅB2C Âíå C2C Â§öÁßç‰∫§ÊòìÊ®°Âºè„ÄÇÂπ≥Âè∞ÂÖ•È©ªÂïÜÂÆ∂Ë∂ÖËøá500‰∏áÔºåSKUÊï∞ÈáèË∂ÖËøá10‰∫øÔºåÊó•ÂùáËÆ¢ÂçïÈáèË∂ÖËøá5000‰∏áÂçï„ÄÇ'),
            ('Smart City Infrastructure', 'Êô∫ÊÖßÂüéÂ∏ÇÂü∫Á°ÄËÆæÊñΩËß£ÂÜ≥ÊñπÊ°àÊèê‰æõÂïÜÔºå‰∏ìÊ≥®‰∫éÁâ©ËÅîÁΩë‰º†ÊÑüÂô®ÁΩëÁªú„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü„ÄÅÂüéÂ∏ÇÂ§ßËÑëÂπ≥Âè∞ÂºÄÂèë„ÄÇÂ∑≤Âú®ÂÖ®ÁêÉ100Â§ö‰∏™ÂüéÂ∏ÇÈÉ®ÁΩ≤Êô∫ÊÖßÂüéÂ∏ÇËß£ÂÜ≥ÊñπÊ°àÔºåÁÆ°ÁêÜË∂ÖËøá1000‰∏á‰∏™IoTËÆæÂ§á„ÄÇ'),
            ('Educational Technology', 'Âú®Á∫øÊïôËÇ≤ÊäÄÊúØËÅîÁõüÔºåÊèê‰æõ K-12 ÂíåÈ´òÁ≠âÊïôËÇ≤Âú®Á∫øÂ≠¶‰π†Âπ≥Âè∞„ÄÇÂπ≥Âè∞Êã•ÊúâË∂ÖËøá10‰∏áÈó®ËØæÁ®ãÔºåÊ≥®ÂÜåÂ≠¶ÂëòË∂ÖËøá1‰∫ø‰∫∫Ôºå‰∏éÂÖ®ÁêÉ500Â§öÊâÄÁü•ÂêçÂ§ßÂ≠¶Âª∫Á´ã‰∫ÜÂêà‰ΩúÂÖ≥Á≥ª„ÄÇ'),
            ('Green Energy Solutions', 'ÂèØÂÜçÁîüËÉΩÊ∫êÁÆ°ÁêÜÁ≥ªÁªüÊèê‰æõÂïÜÔºå‰∏ìÊ≥®‰∫éÂ§™Èò≥ËÉΩ„ÄÅÈ£éËÉΩÂèëÁîµÁ´ôÁöÑÁõëÊéß„ÄÅË∞ÉÂ∫¶Âíå‰ºòÂåñÁÆ°ÁêÜ„ÄÇÁÆ°ÁêÜÁöÑÊ∏ÖÊ¥ÅËÉΩÊ∫êË£ÖÊú∫ÂÆπÈáèË∂ÖËøá100GWÔºåÊØèÂπ¥ÂáèÂ∞ëÁ¢≥ÊéíÊîæË∂ÖËøá5000‰∏áÂê®„ÄÇ'),
            ('CyberSec Defense Corp', 'ÁΩëÁªúÂÆâÂÖ®Èò≤Âæ°ÂÖ¨Âè∏ÔºåÊèê‰æõÊ∏óÈÄèÊµãËØï„ÄÅÊºèÊ¥ûËØÑ‰º∞ÂíåÂÆâÂÖ®Âí®ËØ¢ÊúçÂä°„ÄÇÊã•ÊúâË∂ÖËøá1000ÂêçËÆ§ËØÅÂÆâÂÖ®‰∏ìÂÆ∂ÔºåÊúçÂä°ÂÖ®ÁêÉ500Âº∫‰ºÅ‰∏ö‰∏≠ÁöÑ300Â§öÂÆ∂ÔºåÂπ¥Â§ÑÁêÜÂÆâÂÖ®‰∫ã‰ª∂Ë∂ÖËøá100‰∏áËµ∑„ÄÇ'),
            ('CloudNative Systems', '‰∫ëÂéüÁîüÁ≥ªÁªüÂºÄÂèëÂïÜÔºå‰∏ìÊ≥®‰∫é Kubernetes„ÄÅÂæÆÊúçÂä°Êû∂ÊûÑÂíå DevOps Â∑•ÂÖ∑Èìæ„ÄÇ‰∫ßÂìÅË¢´ÂÖ®ÁêÉË∂ÖËøá10‰∏áÂÆ∂‰ºÅ‰∏öÈááÁî®ÔºåÁÆ°ÁêÜÁöÑÂÆπÂô®ÂÆû‰æãË∂ÖËøá1‰∫ø‰∏™ÔºåÊòØCNCFÁöÑÊ†∏ÂøÉË¥°ÁåÆËÄÖ„ÄÇ'),
            ('DataFlow Analytics', 'Â§ßÊï∞ÊçÆÂàÜÊûêÂπ≥Âè∞ÔºåÊèê‰æõÂÆûÊó∂Êï∞ÊçÆÂ§ÑÁêÜ„ÄÅÂïÜ‰∏öÊô∫ËÉΩÂíåÈ¢ÑÊµãÂàÜÊûêÊúçÂä°„ÄÇÂπ≥Âè∞Êó•Â§ÑÁêÜÊï∞ÊçÆÈáèË∂ÖËøá100PBÔºåÊîØÊåÅË∂ÖËøá1000ÁßçÊï∞ÊçÆÊ∫êÊé•ÂÖ•ÔºåÊúçÂä°ÂÖ®ÁêÉ5000Â§öÂÆ∂‰ºÅ‰∏öÂÆ¢Êà∑„ÄÇ'),
            ('MobileFirst Technologies', 'ÁßªÂä®‰ºòÂÖàÊäÄÊúØÂÖ¨Âè∏Ôºå‰∏ìÊ≥®‰∫é iOS/Android Â∫îÁî®ÂºÄÂèëÂíåË∑®Âπ≥Âè∞Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÂ∑≤ÂºÄÂèëË∂ÖËøá5000Ê¨æÁßªÂä®Â∫îÁî®ÔºåÁ¥ØËÆ°‰∏ãËΩΩÈáèË∂ÖËøá50‰∫øÊ¨°ÔºåÊúàÊ¥ªË∑ÉÁî®Êà∑Ë∂ÖËøá10‰∫ø„ÄÇ'),
            ('Quantum Computing Research', 'ÈáèÂ≠êËÆ°ÁÆóÁ†îÁ©∂Êú∫ÊûÑÔºåËá¥Âäõ‰∫éÈáèÂ≠êÁÆóÊ≥ï„ÄÅÈáèÂ≠êÁ∫†ÈîôÂíåÈáèÂ≠êÁΩëÁªúÁöÑÂâçÊ≤øÁ†îÁ©∂„ÄÇÊã•ÊúâÂÖ®ÁêÉÊúÄÂÖàËøõÁöÑÈáèÂ≠êËÆ°ÁÆóÊú∫‰πã‰∏ÄÔºåÂ∑≤ÂÆûÁé∞1000+ÈáèÂ≠êÊØîÁâπÁöÑÁ®≥ÂÆöËøêÁÆó„ÄÇ'),
            ('Autonomous Vehicles Corp', 'Ëá™Âä®È©æÈ©∂ÊäÄÊúØÂÖ¨Âè∏Ôºå‰∏ìÊ≥®‰∫éL4/L5Á∫ßÂà´Ëá™Âä®È©æÈ©∂Á≥ªÁªüÁ†îÂèë„ÄÇÊµãËØïËΩ¶ÈòüÂ∑≤Á¥ØËÆ°Ë°åÈ©∂Ë∂ÖËøá1‰∫øÂÖ¨ÈáåÔºåÂú®ÂÖ®ÁêÉ20‰∏™ÂüéÂ∏ÇÂºÄÂ±ïÂïÜ‰∏öÂåñËøêËê•„ÄÇ'),
            ('Biotech Innovations', 'ÁîüÁâ©ÊäÄÊúØÂàõÊñ∞‰ºÅ‰∏öÔºå‰∏ìÊ≥®‰∫éÂü∫Âõ†ÁºñËæë„ÄÅÁªÜËÉûÊ≤ªÁñóÂíåÁ≤æÂáÜÂåªÁñó„ÄÇÊã•ÊúâË∂ÖËøá100È°πÁîüÁâ©ÊäÄÊúØ‰∏ìÂà©ÔºåÂ§öÊ¨æÂàõÊñ∞ËçØÁâ©Â∑≤ËøõÂÖ•‰∏¥Â∫äËØïÈ™åÈò∂ÊÆµ„ÄÇ'),
            ('Space Technology Systems', 'Ëà™Â§©ÊäÄÊúØÁ≥ªÁªüÂÖ¨Âè∏ÔºåÊèê‰æõÂç´ÊòüÈÄö‰ø°„ÄÅÈÅ•ÊÑüÊï∞ÊçÆÂíåÂ§™Á©∫Êé¢Á¥¢ÊúçÂä°„ÄÇÂ∑≤ÊàêÂäüÂèëÂ∞ÑË∂ÖËøá500È¢óÂç´ÊòüÔºåÂª∫Á´ã‰∫ÜË¶ÜÁõñÂÖ®ÁêÉÁöÑ‰ΩéËΩ®Âç´Êòü‰∫íËÅîÁΩëÊòüÂ∫ß„ÄÇ'),
        ]
        
        divisions = ['Global Division', 'Asia Pacific', 'EMEA Region', 'Americas', 'R&D Center', 'Digital Platform', 
                     'Cloud Services', 'Security Team', 'Innovation Lab', 'Enterprise Solutions', 'Consumer Products',
                     'Infrastructure Services', 'Data Analytics', 'AI Research', 'Mobile Development', 'DevOps Platform']
        
        # ÈöèÊú∫ÈÄâÊã© 15-20 ‰∏™ÁªÑÁªá
        num_orgs = random.randint(15, 20)
        selected = random.sample(org_templates, min(num_orgs, len(org_templates)))
        
        ids = []
        for name_base, desc in selected:
            division = random.choice(divisions)
            name = f'{name_base} - {division} ({suffix})'
            cur.execute("""
                INSERT INTO organization (name, description, created_at, deleted_at)
                VALUES (%s, %s, NOW() - INTERVAL '%s days', NULL)
                ON CONFLICT DO NOTHING
                RETURNING id
            """, (name, desc, random.randint(0, 365)))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™ÁªÑÁªá\n")
        return ids


    def create_targets(self, org_ids: list) -> list:
        """ÂàõÂª∫Êâ´ÊèèÁõÆÊ†á"""
        print("üéØ ÂàõÂª∫Êâ´ÊèèÁõÆÊ†á...")
        cur = self.conn.cursor()
        
        suffix = random.randint(1000, 9999)
        
        # Ë∂ÖÈïøÂüüÂêçÁîüÊàêÔºåÁõÆÊ†á 200 Â≠óÁ¨¶Â∑¶Âè≥
        # Ê†ºÂºè: {env}-{region}-{service}-{version}.{subdomain}.{company}-{project}-{team}-{suffix}.{domain}{tld}
        envs = ['production', 'staging', 'development', 'testing', 'integration', 'performance', 'security-audit']
        regions = ['us-east-1', 'us-west-2', 'eu-central-1', 'ap-southeast-1', 'ap-northeast-1', 'sa-east-1', 'eu-west-3']
        services = ['api-gateway', 'authentication-service', 'user-management', 'payment-processing', 'notification-center', 'analytics-engine', 'content-delivery', 'search-indexer']
        versions = ['v1', 'v2', 'v3', 'v2-beta', 'v3-alpha', 'v1-legacy', 'v2-stable']
        subdomains = ['internal-services', 'external-facing', 'partner-integration', 'customer-portal', 'admin-dashboard', 'developer-tools', 'monitoring-system']
        companies = ['acme-corporation-international', 'techstart-innovation-labs', 'globalfinance-services-group', 'healthcare-plus-medical-systems', 'ecommerce-platform-solutions', 'smartcity-infrastructure-development', 'cybersecurity-defense-corporation', 'cloudnative-enterprise-systems']
        projects = ['digital-transformation-initiative', 'cloud-migration-project', 'security-enhancement-program', 'customer-experience-platform', 'data-analytics-modernization', 'infrastructure-automation-suite']
        teams = ['engineering-team-alpha', 'devops-squad-bravo', 'security-team-charlie', 'platform-team-delta', 'infrastructure-team-echo']
        domains = ['enterprise', 'platform', 'services', 'solutions', 'systems']
        tlds = ['.com', '.io', '.net', '.org', '.dev', '.app', '.cloud', '.tech', '.systems']
        
        ids = []
        
        # ÈöèÊú∫ÁîüÊàê 100-150 ‰∏™ÂüüÂêçÁõÆÊ†á
        num_domains = random.randint(100, 150)
        used_domains = set()
        
        for i in range(num_domains):
            env = random.choice(envs)
            region = random.choice(regions)
            service = random.choice(services)
            version = random.choice(versions)
            subdomain = random.choice(subdomains)
            company = random.choice(companies)
            project = random.choice(projects)
            team = random.choice(teams)
            domain_name = random.choice(domains)
            tld = random.choice(tlds)
            # ÁîüÊàêË∂ÖÈïøÂüüÂêçÔºåÁ∫¶ 150-200 Â≠óÁ¨¶
            domain = f'{env}-{region}-{service}-{version}.{subdomain}.{company}-{project}-{team}-{suffix}.{domain_name}{tld}'
            
            if domain in used_domains:
                continue
            used_domains.add(domain)
            
            cur.execute("""
                INSERT INTO target (name, type, created_at, last_scanned_at, deleted_at)
                VALUES (%s, 'domain', NOW() - INTERVAL '%s days', NOW() - INTERVAL '%s days', NULL)
                ON CONFLICT DO NOTHING
                RETURNING id
            """, (domain, random.randint(30, 365), random.randint(0, 30)))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                # ÈöèÊú∫ÂÖ≥ËÅîÂà∞ÁªÑÁªá
                if org_ids and random.random() > 0.3:  # 70% Ê¶ÇÁéáÂÖ≥ËÅî
                    org_id = random.choice(org_ids)
                    cur.execute("""
                        INSERT INTO organization_targets (organization_id, target_id)
                        VALUES (%s, %s)
                        ON CONFLICT DO NOTHING
                    """, (org_id, row[0]))
        
        # ÈöèÊú∫ÁîüÊàê 50-80 ‰∏™ IP ÁõÆÊ†á
        num_ips = random.randint(50, 80)
        for _ in range(num_ips):
            # ‰ΩøÁî®ÊñáÊ°£‰øùÁïôÁöÑ IP ËåÉÂõ¥
            ip_ranges = [
                (203, 0, 113),   # TEST-NET-3
                (198, 51, 100),  # TEST-NET-2
                (192, 0, 2),     # TEST-NET-1
            ]
            base = random.choice(ip_ranges)
            ip = f'{base[0]}.{base[1]}.{base[2]}.{random.randint(1, 254)}'
            
            cur.execute("""
                INSERT INTO target (name, type, created_at, last_scanned_at, deleted_at)
                VALUES (%s, 'ip', NOW() - INTERVAL '%s days', NOW() - INTERVAL '%s days', NULL)
                ON CONFLICT DO NOTHING
                RETURNING id
            """, (ip, random.randint(30, 365), random.randint(0, 30)))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
        
        # ÈöèÊú∫ÁîüÊàê 30-50 ‰∏™ CIDR ÁõÆÊ†á
        num_cidrs = random.randint(30, 50)
        cidr_bases = ['10.0', '172.16', '172.17', '172.18', '192.168']
        for _ in range(num_cidrs):
            base = random.choice(cidr_bases)
            third_octet = random.randint(0, 255)
            mask = random.choice([24, 25, 26, 27, 28])
            cidr = f'{base}.{third_octet}.0/{mask}'
            
            cur.execute("""
                INSERT INTO target (name, type, created_at, last_scanned_at, deleted_at)
                VALUES (%s, 'cidr', NOW() - INTERVAL '%s days', NOW() - INTERVAL '%s days', NULL)
                ON CONFLICT DO NOTHING
                RETURNING id
            """, (cidr, random.randint(30, 365), random.randint(0, 30)))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™Êâ´ÊèèÁõÆÊ†á\n")
        return ids

    def create_scans(self, target_ids: list, engine_ids: list, worker_ids: list) -> list:
        """ÂàõÂª∫Êâ´Êèè‰ªªÂä°"""
        print("üîç ÂàõÂª∫Êâ´Êèè‰ªªÂä°...")
        cur = self.conn.cursor()
        
        if not target_ids or not engine_ids:
            print("  ‚ö† Áº∫Â∞ëÁõÆÊ†áÊàñÂºïÊìéÔºåË∑≥Ëøá\n")
            return []
        
        statuses = ['cancelled', 'completed', 'failed', 'initiated', 'running']
        status_weights = [0.05, 0.6, 0.1, 0.1, 0.15]  # completed Âç†ÊØîÊúÄÈ´ò
        stages = ['subdomain_discovery', 'port_scanning', 'web_discovery', 'vulnerability_scanning', 'directory_bruteforce', 'endpoint_discovery']
        
        error_messages = [
            'Connection timeout while scanning target. Please check network connectivity.',
            'DNS resolution failed for target domain.',
            'Rate limit exceeded. Scan paused and will resume automatically.',
            'Worker node disconnected during scan execution.',
            'Insufficient disk space on worker node.',
            'Target returned too many errors, scan aborted.',
            'Authentication failed for protected resources.',
        ]
        
        ids = []
        # ÈöèÊú∫ÈÄâÊã©ÁõÆÊ†áÊï∞Èáè - Â¢ûÂä†Âà∞ 80-120 ‰∏™
        num_targets = min(random.randint(80, 120), len(target_ids))
        selected_targets = random.sample(target_ids, num_targets)
        
        for target_id in selected_targets:
            # ÊØè‰∏™ÁõÆÊ†áÈöèÊú∫ 3-15 ‰∏™Êâ´Êèè‰ªªÂä°
            num_scans = random.randint(3, 15)
            for _ in range(num_scans):
                status = random.choices(statuses, weights=status_weights)[0]
                engine_id = random.choice(engine_ids)
                worker_id = random.choice(worker_ids) if worker_ids else None
                
                progress = random.randint(10, 95) if status == 'running' else (100 if status == 'completed' else random.randint(0, 50))
                stage = random.choice(stages) if status == 'running' else ''
                error_msg = random.choice(error_messages) if status == 'failed' else ''
                
                # ÈöèÊú∫ÁîüÊàêÊõ¥ÁúüÂÆûÁöÑÁªüËÆ°Êï∞ÊçÆ
                subdomains = random.randint(50, 2000)
                websites = random.randint(10, 500)
                endpoints = random.randint(100, 5000)
                ips = random.randint(20, 300)
                directories = random.randint(200, 8000)
                vulns_critical = random.randint(0, 20)
                vulns_high = random.randint(0, 50)
                vulns_medium = random.randint(0, 100)
                vulns_low = random.randint(0, 150)
                vulns_total = vulns_critical + vulns_high + vulns_medium + vulns_low + random.randint(0, 100)  # info
                
                days_ago = random.randint(0, 90)
                
                cur.execute("""
                    INSERT INTO scan (
                        target_id, engine_id, status, worker_id, progress, current_stage,
                        results_dir, error_message, container_ids, stage_progress,
                        cached_subdomains_count, cached_websites_count, cached_endpoints_count,
                        cached_ips_count, cached_directories_count, cached_vulns_total,
                        cached_vulns_critical, cached_vulns_high, cached_vulns_medium, cached_vulns_low,
                        created_at, stopped_at, deleted_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        NOW() - INTERVAL '%s days', %s, NULL
                    )
                    RETURNING id
                """, (
                    target_id, engine_id, status, worker_id, progress, stage,
                    f'/app/results/scan_{target_id}_{random.randint(1000, 9999)}', error_msg, '{}', '{}',
                    subdomains, websites, endpoints, ips, directories, vulns_total,
                    vulns_critical, vulns_high, vulns_medium, vulns_low,
                    days_ago,
                    datetime.now() - timedelta(days=days_ago, hours=random.randint(0, 23)) if status in ['completed', 'failed', 'cancelled'] else None
                ))
                row = cur.fetchone()
                if row:
                    ids.append(row[0])
                    
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™Êâ´Êèè‰ªªÂä°\n")
        return ids

    def create_scheduled_scans(self, org_ids: list, target_ids: list, engine_ids: list):
        """ÂàõÂª∫ÂÆöÊó∂Êâ´Êèè‰ªªÂä°"""
        print("‚è∞ ÂàõÂª∫ÂÆöÊó∂Êâ´Êèè‰ªªÂä°...")
        cur = self.conn.cursor()
        
        if not engine_ids:
            print("  ‚ö† Áº∫Â∞ëÂºïÊìéÔºåË∑≥Ëøá\n")
            return
        
        suffix = random.randint(1000, 9999)
        
        schedule_templates = [
            ('Daily-Full-Security-Assessment-Enterprise-Wide-Comprehensive-Vulnerability-Detection', '0 {hour} * * *'),
            ('Weekly-Vulnerability-Scan-Critical-Infrastructure-Protection-Program', '0 {hour} * * {dow}'),
            ('Monthly-Penetration-Testing-External-Attack-Surface-Management', '0 {hour} {dom} * *'),
            ('Hourly-Quick-Reconnaissance-Real-Time-Threat-Intelligence-Gathering', '{min} * * * *'),
            ('Bi-Weekly-Compliance-Check-Regulatory-Standards-Verification-Audit', '0 {hour} 1,15 * *'),
            ('Quarterly-Infrastructure-Audit-Network-Security-Posture-Assessment', '0 {hour} 1 1,4,7,10 *'),
            ('Daily-API-Security-Scan-RESTful-GraphQL-Endpoint-Protection', '{min} {hour} * * *'),
            ('Weekly-Web-Application-Scan-OWASP-Top-10-Vulnerability-Detection', '0 {hour} * * {dow}'),
            ('Nightly-Asset-Discovery-Shadow-IT-Detection-Inventory-Management', '0 {hour} * * *'),
            ('Weekend-Deep-Scan-Intensive-Security-Analysis-Full-Coverage', '0 {hour} * * 0,6'),
            ('Business-Hours-Monitor-Real-Time-Security-Event-Detection-Response', '0 9-17 * * 1-5'),
            ('Off-Hours-Intensive-Scan-Low-Impact-Comprehensive-Assessment', '0 {hour} * * *'),
            ('Continuous-Monitoring-Zero-Day-Vulnerability-Detection-System', '{min} * * * *'),
            ('Cloud-Infrastructure-Security-Assessment-AWS-Azure-GCP-Multi-Cloud', '0 {hour} * * *'),
            ('Container-Security-Scan-Kubernetes-Docker-Image-Vulnerability-Check', '0 {hour} * * {dow}'),
            ('Database-Security-Audit-SQL-Injection-Data-Exposure-Prevention', '0 {hour} {dom} * *'),
            ('Network-Perimeter-Scan-Firewall-Configuration-Compliance-Check', '0 {hour} * * *'),
            ('SSL-TLS-Certificate-Monitoring-Expiration-Vulnerability-Detection', '0 {hour} * * *'),
            ('DNS-Security-Assessment-Zone-Transfer-Subdomain-Takeover-Check', '0 {hour} * * {dow}'),
            ('Email-Security-Scan-SPF-DKIM-DMARC-Configuration-Verification', '0 {hour} {dom} * *'),
            ('Mobile-Application-Security-Testing-iOS-Android-API-Assessment', '0 {hour} * * *'),
            ('IoT-Device-Security-Scan-Firmware-Vulnerability-Network-Exposure', '0 {hour} * * {dow}'),
            ('Third-Party-Risk-Assessment-Vendor-Security-Posture-Evaluation', '0 {hour} 1 * *'),
            ('Incident-Response-Readiness-Security-Control-Effectiveness-Test', '0 {hour} 15 * *'),
            ('Ransomware-Prevention-Scan-Backup-Integrity-Recovery-Verification', '0 {hour} * * *'),
        ]
        
        # ÈöèÊú∫ÈÄâÊã© 40-50 ‰∏™ÂÆöÊó∂‰ªªÂä°
        num_schedules = random.randint(40, 50)
        selected = random.sample(schedule_templates, min(num_schedules, len(schedule_templates)))
        
        count = 0
        for name_base, cron_template in selected:
            name = f'{name_base}-{suffix}-{count:02d}'
            cron = cron_template.format(
                hour=random.randint(0, 23),
                min=random.randint(0, 59),
                dow=random.randint(0, 6),
                dom=random.randint(1, 28)
            )
            enabled = random.random() > 0.3  # 70% ÂêØÁî®
            
            engine_id = random.choice(engine_ids)
            # ÈöèÊú∫ÂÜ≥ÂÆöÂÖ≥ËÅîÁªÑÁªáËøòÊòØÁõÆÊ†á
            if org_ids and target_ids:
                if random.random() > 0.5:
                    org_id = random.choice(org_ids)
                    target_id = None
                else:
                    org_id = None
                    target_id = random.choice(target_ids)
            elif org_ids:
                org_id = random.choice(org_ids)
                target_id = None
            elif target_ids:
                org_id = None
                target_id = random.choice(target_ids)
            else:
                org_id = None
                target_id = None
            
            run_count = random.randint(0, 200)
            has_run = random.random() > 0.2  # 80% Â∑≤ËøêË°åËøá
            
            cur.execute("""
                INSERT INTO scheduled_scan (
                    name, engine_id, organization_id, target_id, cron_expression, is_enabled,
                    run_count, last_run_time, next_run_time, created_at, updated_at
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW() - INTERVAL '%s days', NOW())
                ON CONFLICT DO NOTHING
            """, (
                name, engine_id, org_id, target_id, cron, enabled,
                run_count if has_run else 0,
                datetime.now() - timedelta(days=random.randint(0, 14), hours=random.randint(0, 23)) if has_run else None,
                datetime.now() + timedelta(hours=random.randint(1, 336))  # ÊúÄÂ§ö 2 Âë®Âêé
            , random.randint(30, 180)))
            count += 1
            
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÂÆöÊó∂Êâ´Êèè‰ªªÂä°\n")


    def create_subdomains(self, target_ids: list):
        """ÂàõÂª∫Â≠êÂüüÂêç"""
        print("üåê ÂàõÂª∫Â≠êÂüüÂêç...")
        cur = self.conn.cursor()
        
        prefixes = [
            # Âü∫Á°ÄÊúçÂä°
            'api', 'admin', 'portal', 'dashboard', 'app', 'mobile', 'staging', 'dev',
            'test', 'qa', 'uat', 'beta', 'alpha', 'demo', 'sandbox', 'internal',
            'secure', 'auth', 'login', 'sso', 'oauth', 'identity', 'accounts',
            'mail', 'smtp', 'imap', 'webmail', 'ftp', 'sftp', 'files', 'storage',
            'cdn', 'static', 'assets', 'media', 'db', 'database', 'mysql', 'postgres',
            'redis', 'mongo', 'elastic', 'vpn', 'remote', 'gateway', 'proxy',
            'monitoring', 'metrics', 'grafana', 'prometheus', 'kibana', 'logs',
            'jenkins', 'ci', 'cd', 'gitlab', 'jira', 'confluence', 'kubernetes', 'k8s',
            'www', 'www2', 'www3', 'ns1', 'ns2', 'mx', 'mx1', 'mx2', 'autodiscover',
            'webdisk', 'cpanel', 'whm', 'webmail2', 'email', 'smtp2', 'pop', 'pop3',
            'imap2', 'calendar', 'contacts', 'drive', 'docs', 'sheets', 'slides',
            'meet', 'chat', 'teams', 'slack', 'discord', 'zoom', 'video', 'stream',
            'blog', 'news', 'press', 'media2', 'images', 'img', 'photos', 'video2',
            'shop', 'store', 'cart', 'checkout', 'pay', 'payment', 'billing', 'invoice',
            'support', 'help', 'helpdesk', 'ticket', 'tickets', 'status', 'health',
            'api-v1', 'api-v2', 'api-v3', 'graphql', 'rest', 'soap', 'rpc', 'grpc',
            # Êâ©Â±ïÊúçÂä°
            'analytics', 'reporting', 'bi', 'data', 'warehouse', 'etl', 'pipeline',
            'ml', 'ai', 'inference', 'training', 'model', 'prediction', 'recommendation',
            'search', 'solr', 'elasticsearch', 'opensearch', 'algolia', 'typesense',
            'cache', 'memcached', 'varnish', 'haproxy', 'loadbalancer', 'nginx-lb',
            'queue', 'rabbitmq', 'kafka', 'pulsar', 'nats', 'activemq', 'sqs',
            'workflow', 'airflow', 'prefect', 'dagster', 'temporal', 'conductor',
            'registry', 'harbor', 'nexus', 'artifactory', 'pypi', 'npm-registry',
            'vault', 'secrets', 'keycloak', 'okta', 'auth0', 'cognito', 'firebase-auth',
            'notification', 'push', 'websocket', 'socket', 'realtime', 'pubsub',
            'backup', 'archive', 'snapshot', 'restore', 'disaster-recovery', 'dr',
            'audit', 'compliance', 'security', 'waf', 'firewall', 'ids', 'ips',
            'tracing', 'jaeger', 'zipkin', 'tempo', 'honeycomb', 'lightstep',
            'config', 'consul', 'etcd', 'zookeeper', 'nacos', 'apollo-config',
            'service-mesh', 'istio', 'linkerd', 'envoy', 'traefik', 'kong',
        ]
        
        # ‰∫åÁ∫ßÂâçÁºÄÔºåÁî®‰∫éÁîüÊàêÊõ¥Â§çÊùÇÁöÑÂ≠êÂüüÂêç
        secondary_prefixes = ['', 'prod-', 'dev-', 'staging-', 'test-', 'int-', 'ext-', 'us-', 'eu-', 'ap-', 
                              'us-east-', 'us-west-', 'eu-central-', 'ap-southeast-', 'ap-northeast-',
                              'primary-', 'secondary-', 'backup-', 'dr-', 'canary-', 'blue-', 'green-']
        
        # Ëé∑ÂèñÂüüÂêçÁõÆÊ†á
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        for target_id, target_name in domain_targets:
            # ÊØè‰∏™ÁõÆÊ†áÈöèÊú∫ 80-150 ‰∏™Â≠êÂüüÂêç
            num = random.randint(80, 150)
            selected = random.sample(prefixes, min(num, len(prefixes)))
            
            for prefix in selected:
                # ÈöèÊú∫Ê∑ªÂä†‰∫åÁ∫ßÂâçÁºÄ
                sec_prefix = random.choice(secondary_prefixes) if random.random() > 0.7 else ''
                subdomain_name = f'{sec_prefix}{prefix}.{target_name}'
                days_ago = random.randint(0, 90)
                batch_data.append((subdomain_name, target_id, days_ago))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO subdomain (name, target_id, created_at)
                VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, NOW() - INTERVAL '%s days')")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™Â≠êÂüüÂêç\n")

    def create_websites(self, target_ids: list) -> list:
        """ÂàõÂª∫ÁΩëÁ´ô"""
        print("üåç ÂàõÂª∫ÁΩëÁ´ô...")
        cur = self.conn.cursor()
        
        titles = [
            'Enterprise Resource Planning System - Comprehensive Dashboard | Acme Corporation International Global Operations Management Portal v3.2.1 - Integrated Business Process Automation and Real-time Analytics Platform for Enterprise-wide Resource Optimization',
            'Customer Relationship Management Platform - Secure Login Portal | Multi-Factor Authentication Enabled - Advanced Customer Data Analytics and Sales Pipeline Management System with AI-Powered Insights and Predictive Modeling',
            'Human Resources Information System - Employee Self Service Portal v3.2.1 | Comprehensive Payroll Benefits Time-Off Management - Performance Review Talent Acquisition Onboarding Workflow Automation Platform',
            'Supply Chain Management - Global Logistics Tracking Dashboard | Real-time Updates - Worldwide Distribution Network Monitor with Predictive Analytics Inventory Optimization and Supplier Relationship Management',
            'Business Intelligence Analytics - Executive Summary Report Generator | Advanced Data Visualization Decision Support System - Machine Learning Powered Predictive Analytics and Custom Dashboard Builder',
            'Content Management System - Admin Panel | Headless CMS API Gateway - Multi-tenant Enterprise Publishing Platform with Workflow Automation Digital Asset Management and Multi-language Support',
            'Project Management Collaboration Tools - Team Workspace | Agile Board - Sprint Planning Resource Allocation Time Tracking Budget Management Gantt Charts Kanban Boards and Team Communication Hub',
            'E-Commerce Platform - Product Catalog Management | Inventory Control - Order Processing Fulfillment System with Multi-channel Sales Integration Payment Gateway and Customer Analytics Dashboard',
            'Financial Trading Platform - Real-time Market Data Dashboard | Portfolio Management Risk Analysis System - Algorithmic Trading Support Technical Analysis Tools and Regulatory Compliance Reporting',
            'Healthcare Patient Management System - Electronic Health Records | HIPAA Compliant Medical Information Portal - Appointment Scheduling Prescription Management Lab Results Integration and Telemedicine Support',
        ]
        
        webservers = ['nginx/1.24.0', 'nginx/1.25.3', 'nginx/1.26.0', 'Apache/2.4.57', 'Apache/2.4.58', 'Apache/2.4.59', 
                      'Microsoft-IIS/10.0', 'Microsoft-IIS/8.5', 'Microsoft-IIS/7.5', 'cloudflare', 
                      'gunicorn/21.2.0', 'gunicorn/22.0.0', 'gunicorn/23.0.0', 'uvicorn/0.24.0', 'uvicorn/0.25.0',
                      'Caddy/2.7.5', 'Caddy/2.8.0', 'LiteSpeed', 'LiteSpeed/6.1', 'OpenResty/1.21.4', 'OpenResty/1.25.3',
                      'Tomcat/10.1.15', 'Tomcat/9.0.83', 'Jetty/11.0.18', 'Jetty/12.0.5', 'WildFly/30.0.0',
                      'Kestrel', 'Puma/6.4.0', 'Unicorn/6.1.0', 'Passenger/6.0.18', 'Waitress/2.1.2',
                      'Hypercorn/0.16.0', 'Daphne/4.0.0', 'Twisted/23.10.0', 'CherryPy/18.9.0']
        tech_stacks = [
            ['React 18.2.0', 'React Router 6.21', 'Redux Toolkit 2.0', 'RTK Query', 'Node.js 20.10 LTS', 'Express 4.18.2', 'MongoDB 7.0.4', 'Mongoose 8.0', 'Redis 7.2.3', 'Bull Queue 4.12', 'Nginx 1.25.3', 'Docker 24.0', 'Kubernetes 1.28.4', 'Helm 3.13', 'Prometheus 2.48', 'Grafana 10.2'],
            ['Vue.js 3.4.5', 'Vuex 4.1', 'Vue Router 4.2', 'Pinia 2.1', 'Nuxt 3.9.0', 'Django 5.0.1', 'Django REST Framework 3.14', 'PostgreSQL 16.1', 'Celery 5.3.6', 'RabbitMQ 3.12.10', 'Gunicorn 21.2', 'Nginx 1.25', 'Docker Compose', 'Prometheus', 'Grafana', 'Sentry'],
            ['Angular 17.1.0', 'NgRx 17.0', 'RxJS 7.8', 'Angular Material 17', 'Spring Boot 3.2.1', 'Spring Security 6.2', 'Spring Data JPA', 'MySQL 8.2.0', 'Elasticsearch 8.11.3', 'Apache Kafka 3.6.1', 'Grafana 10.2', 'Jenkins 2.426', 'SonarQube 10.3', 'JUnit 5.10', 'Mockito 5.8'],
            ['Next.js 14.0.4', 'React 18.2', 'TypeScript 5.3', 'Tailwind CSS 3.4', 'FastAPI 0.109.0', 'Pydantic 2.5', 'SQLAlchemy 2.0', 'Redis 7.2', 'PostgreSQL 16', 'Docker 24.0', 'Kubernetes 1.28', 'Istio 1.20', 'ArgoCD 2.9', 'Prometheus', 'Grafana', 'Jaeger'],
            ['Svelte 4.2.8', 'SvelteKit 2.0.6', 'TypeScript 5.3', 'Tailwind CSS 3.4', 'Go 1.21.5', 'Gin 1.9', 'GORM 1.25', 'CockroachDB 23.2', 'NATS 2.10.7', 'Traefik 3.0', 'Consul 1.17', 'Vault 1.15', 'Terraform 1.6', 'Prometheus', 'Grafana', 'Loki'],
            ['React 18.2.0', 'NestJS 10.3.0', 'TypeORM 0.3.17', 'GraphQL 16.8', 'Apollo Server 4.10', 'PostgreSQL 16.1', 'Bull 4.12', 'Redis 7.2.3', 'Swagger 7.1', 'Jest 29.7', 'Supertest 6.3', 'Docker', 'Kubernetes', 'Helm', 'ArgoCD', 'Datadog'],
            ['Vue.js 3.4.5', 'Inertia.js 1.0', 'Laravel 10.40', 'PHP 8.3', 'MySQL 8.2', 'Redis 7.2', 'Laravel Horizon 5.21', 'Laravel Telescope', 'Nginx 1.25', 'Vite 5.0', 'PHPUnit 10.5', 'Pest 2.28', 'Docker', 'GitHub Actions', 'Sentry', 'New Relic'],
            ['Angular 17.1', 'NgRx 17.0', '.NET 8.0', 'Entity Framework Core 8.0', 'ASP.NET Core 8.0', 'SQL Server 2022', 'Azure Service Bus', 'Azure Functions', 'IIS 10', 'SignalR 8.0', 'xUnit 2.6', 'Moq 4.20', 'Azure DevOps', 'Application Insights', 'Azure Monitor'],
        ]
        
        # ÁúüÂÆûÁöÑ body preview ÂÜÖÂÆπ
        body_previews = [
            '<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Login - Enterprise Portal</title><link rel="stylesheet" href="/assets/css/main.css"></head><body><div id="app"></div><script src="/assets/js/bundle.js"></script></body></html>',
            '<!DOCTYPE html><html><head><title>Dashboard</title><meta name="description" content="Enterprise management dashboard for monitoring and analytics"><link rel="icon" href="/favicon.ico"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id="root"></div></body></html>',
            '{"status":"ok","version":"2.4.1","environment":"production","timestamp":"2024-12-22T10:30:00Z","services":{"database":"healthy","cache":"healthy","queue":"healthy"},"uptime":864000}',
            '<!DOCTYPE html><html><head><meta charset="utf-8"><title>403 Forbidden</title></head><body><h1>403 Forbidden</h1><p>You don\'t have permission to access this resource. Please contact the administrator if you believe this is an error.</p><hr><address>nginx/1.24.0</address></body></html>',
            '<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><title>Á≥ªÁªüÁª¥Êä§‰∏≠</title><style>body{font-family:Arial,sans-serif;text-align:center;padding:50px;}</style></head><body><h1>Á≥ªÁªüÊ≠£Âú®Áª¥Êä§‰∏≠</h1><p>È¢ÑËÆ°ÊÅ¢Â§çÊó∂Èó¥Ôºö2024-12-23 08:00</p></body></html>',
            '{"error":"Unauthorized","message":"Invalid or expired authentication token. Please login again.","code":"AUTH_001","timestamp":"2024-12-22T15:45:30.123Z","path":"/api/v1/users/profile"}',
            '<!DOCTYPE html><html><head><title>Welcome to nginx!</title><style>body{width:35em;margin:0 auto;font-family:Tahoma,Verdana,Arial,sans-serif;}</style></head><body><h1>Welcome to nginx!</h1><p>If you see this page, the nginx web server is successfully installed and working.</p></body></html>',
            '<?xml version="1.0" encoding="UTF-8"?><error><code>500</code><message>Internal Server Error</message><details>An unexpected error occurred while processing your request. Please try again later or contact support.</details><requestId>req_abc123xyz789</requestId></error>',
            '<!DOCTYPE html><html><head><meta http-equiv="refresh" content="0;url=https://login.example.com/sso"><title>Redirecting...</title></head><body><p>Redirecting to login page...</p><a href="https://login.example.com/sso">Click here if not redirected</a></body></html>',
            '{"data":{"user":{"id":12345,"username":"admin","email":"admin@example.com","role":"administrator","lastLogin":"2024-12-21T18:30:00Z","permissions":["read","write","delete","admin"]},"token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."}}',
            '<!DOCTYPE html><html><head><title>API Documentation - Swagger UI</title><link rel="stylesheet" type="text/css" href="/swagger-ui.css"><link rel="icon" type="image/png" href="/favicon-32x32.png"></head><body><div id="swagger-ui"></div><script src="/swagger-ui-bundle.js"></script></body></html>',
            '{"openapi":"3.0.3","info":{"title":"Enterprise API","description":"RESTful API for enterprise resource management","version":"1.0.0","contact":{"email":"api-support@example.com"}},"servers":[{"url":"https://api.example.com/v1"}]}',
            '<!DOCTYPE html><html><head><title>404 Not Found</title><style>*{margin:0;padding:0;}body{background:#f1f1f1;font-family:Arial;}.container{max-width:600px;margin:100px auto;text-align:center;}</style></head><body><div class="container"><h1>404</h1><p>Page not found</p></div></body></html>',
            'PING OK - Packet loss = 0%, RTA = 0.45 ms|rta=0.450000ms;100.000000;500.000000;0.000000 pl=0%;20;60;0',
            '{"metrics":{"requests_total":1234567,"requests_per_second":450.5,"avg_response_time_ms":23.4,"error_rate":0.02,"active_connections":1250,"memory_usage_mb":2048,"cpu_usage_percent":45.6}}',
            '<!DOCTYPE html><html><head><title>Under Construction</title></head><body style="background:#000;color:#0f0;font-family:monospace;padding:20px;"><pre>  _   _           _             ____                _                   _   _             \n | | | |_ __   __| | ___ _ __  / ___|___  _ __  ___| |_ _ __ _   _  ___| |_(_) ___  _ __  \n | | | | \'_ \\ / _` |/ _ \\ \'__|| |   / _ \\| \'_ \\/ __| __| \'__| | | |/ __| __| |/ _ \\| \'_ \\ \n | |_| | | | | (_| |  __/ |   | |__| (_) | | | \\__ \\ |_| |  | |_| | (__| |_| | (_) | | | |\n  \\___/|_| |_|\\__,_|\\___|_|    \\____\\___/|_| |_|___/\\__|_|   \\__,_|\\___|\\__|_|\\___/|_| |_|\n</pre><p>Coming Soon...</p></body></html>',
            '{"success":false,"error":{"type":"ValidationError","message":"Request validation failed","details":[{"field":"email","message":"Invalid email format"},{"field":"password","message":"Password must be at least 8 characters"}]}}',
            'Server: Apache/2.4.57 (Ubuntu)\nX-Powered-By: PHP/8.2.0\nContent-Type: text/html; charset=UTF-8\nSet-Cookie: PHPSESSID=abc123; path=/; HttpOnly; Secure\n\n<!DOCTYPE html><html><head><title>phpinfo()</title></head><body>PHP Version 8.2.0</body></html>',
        ]
        
        # Ëé∑ÂèñÂüüÂêçÁõÆÊ†á
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL LIMIT 80")
        domain_targets = cur.fetchall()
        
        batch_data = []
        for target_id, target_name in domain_targets:
            for i in range(random.randint(15, 30)):
                protocol = random.choice(['https', 'http'])
                port = random.choice([80, 443, 8080, 8443, 3000])
                
                if port in [80, 443]:
                    url = f'{protocol}://{target_name}/'
                else:
                    url = f'{protocol}://{target_name}:{port}/'
                
                if i > 0:
                    path = random.choice(['admin/', 'api/', 'portal/', 'dashboard/'])
                    url = f'{protocol}://{target_name}:{port}/{path}'
                
                batch_data.append((
                    url, target_id, target_name, random.choice(titles),
                    random.choice(webservers), random.choice(tech_stacks),
                    random.choice([200, 301, 302, 403, 404]),
                    random.randint(1000, 500000), 'text/html; charset=utf-8',
                    f'https://{target_name}/login' if random.choice([True, False]) else '',
                    random.choice(body_previews),
                    random.choice([True, False, None])
                ))
        
        # ÊâπÈáèÊèíÂÖ•
        ids = []
        if batch_data:
            execute_values(cur, """
                INSERT INTO website (
                    url, target_id, host, title, webserver, tech, status_code,
                    content_length, content_type, location, body_preview, vhost,
                    created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
                RETURNING id
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
            ids = [row[0] for row in cur.fetchall()]
                    
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(batch_data)} ‰∏™ÁΩëÁ´ô\n")
        return ids

    def create_endpoints(self, target_ids: list):
        """ÂàõÂª∫Á´ØÁÇπ"""
        print("üîó ÂàõÂª∫Á´ØÁÇπ...")
        cur = self.conn.cursor()
        
        paths = [
            '/api/v1/users/authentication/login', '/api/v1/users/authentication/logout',
            '/api/v1/users/profile/settings/preferences', '/api/v2/products/catalog/categories/list',
            '/api/v2/orders/checkout/payment-processing', '/api/v3/analytics/dashboard/metrics/summary',
            '/graphql/query', '/graphql/mutation', '/admin/dashboard/overview',
            '/admin/users/management/list', '/admin/settings/configuration/system',
            '/portal/customer/account/billing-history', '/internal/health/readiness-check',
            '/internal/metrics/prometheus-endpoint', '/webhook/payment/stripe/callback',
            '/oauth/authorize', '/oauth/token', '/swagger/v1/swagger.json', '/openapi/v3/api-docs',
            # Êâ©Â±ïË∑ØÂæÑ
            '/api/v1/organizations/enterprise/departments/teams/members/list',
            '/api/v2/inventory/warehouse/locations/zones/shelves/products',
            '/api/v3/reporting/financial/quarterly/revenue/breakdown/by-region',
            '/admin/system/configuration/security/authentication/providers/saml',
            '/admin/audit/logs/security/events/authentication/failures/export',
            '/portal/enterprise/dashboard/analytics/performance/metrics/realtime',
            '/internal/monitoring/infrastructure/kubernetes/pods/health/status',
            '/webhook/integration/salesforce/opportunity/stage-change/notification',
            '/api/v1/customers/enterprise/contracts/subscriptions/billing/invoices',
            '/api/v2/shipping/carriers/fedex/tracking/packages/delivery-status',
            '/api/v3/notifications/channels/email/templates/marketing/campaigns',
            '/admin/content/management/pages/blog/articles/drafts/review-queue',
            '/portal/support/tickets/priority/critical/escalation/management',
            '/internal/jobs/scheduler/cron/tasks/execution/history/logs',
            '/api/v1/search/elasticsearch/indices/products/documents/query',
            '/api/v2/cache/redis/clusters/primary/keys/invalidation/batch',
            '/api/v3/queue/rabbitmq/exchanges/notifications/bindings/routes',
            '/admin/database/migrations/schema/versions/rollback/history',
            '/portal/analytics/google/tag-manager/containers/tags/triggers',
            '/internal/secrets/vault/kv/applications/credentials/rotation',
        ]
        
        gf_patterns = [['debug', 'config'], ['api', 'json'], ['upload', 'file'], ['admin'], ['auth'], 
                       ['secrets', 'credentials'], ['backup', 'archive'], ['debug', 'trace'], []]
        
        # ÁúüÂÆûÁöÑ API ÂìçÂ∫î body preview
        body_previews = [
            '{"status":"success","data":{"user_id":12345,"username":"john_doe","email":"john@example.com","role":"user","created_at":"2024-01-15T10:30:00Z","last_login":"2024-12-22T08:45:00Z"}}',
            '{"success":true,"message":"Authentication successful","token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c","expires_in":3600}',
            '{"error":"Unauthorized","code":"AUTH_FAILED","message":"Invalid credentials provided. Please check your username and password.","timestamp":"2024-12-22T15:30:45.123Z","request_id":"req_abc123xyz"}',
            '{"data":{"products":[{"id":1,"name":"Enterprise License","price":999.99,"currency":"USD"},{"id":2,"name":"Professional License","price":499.99,"currency":"USD"},{"id":3,"name":"Basic License","price":99.99,"currency":"USD"}],"total":3,"page":1,"per_page":10}}',
            '{"health":{"status":"healthy","version":"2.4.1","uptime":"15d 6h 32m","checks":{"database":"ok","redis":"ok","elasticsearch":"ok","rabbitmq":"ok"},"memory":{"used":"2.1GB","total":"8GB"},"cpu":"23%"}}',
            '{"errors":[{"field":"email","message":"Email address is already registered"},{"field":"password","message":"Password must contain at least one uppercase letter, one number, and one special character"}],"code":"VALIDATION_ERROR"}',
            '{"result":{"query":"SELECT * FROM users WHERE id = ?","rows_affected":1,"execution_time_ms":12,"cached":false},"data":[{"id":1,"name":"Admin User","status":"active"}]}',
            '<!DOCTYPE html><html><head><title>GraphQL Playground</title><link rel="stylesheet" href="/graphql/playground.css"></head><body><div id="root"><div class="loading">Loading GraphQL Playground...</div></div><script src="/graphql/playground.js"></script></body></html>',
            '{"swagger":"2.0","info":{"title":"Enterprise API","description":"RESTful API for enterprise resource management","version":"1.0.0"},"host":"api.example.com","basePath":"/v1","schemes":["https"],"paths":{"/users":{"get":{"summary":"List users"}}}}',
            '{"openapi":"3.0.3","info":{"title":"User Management API","version":"2.0.0","description":"API for managing user accounts and permissions","contact":{"email":"api@example.com"}},"servers":[{"url":"https://api.example.com/v2","description":"Production server"}]}',
            '{"metrics":{"http_requests_total":{"value":1523456,"labels":{"method":"GET","status":"200"}},"http_request_duration_seconds":{"value":0.023,"labels":{"quantile":"0.99"}},"process_cpu_seconds_total":{"value":12345.67}}}',
            '# HELP http_requests_total Total number of HTTP requests\n# TYPE http_requests_total counter\nhttp_requests_total{method="GET",status="200"} 1523456\nhttp_requests_total{method="POST",status="201"} 45678\n# HELP http_request_duration_seconds HTTP request latency\nhttp_request_duration_seconds{quantile="0.5"} 0.012',
            '{"order":{"id":"ORD-2024-123456","status":"processing","items":[{"sku":"PROD-001","name":"Widget Pro","quantity":2,"price":49.99}],"subtotal":99.98,"tax":8.00,"shipping":5.99,"total":113.97,"created_at":"2024-12-22T14:30:00Z"}}',
            '{"session":{"id":"sess_abc123xyz789","user_id":12345,"ip_address":"192.168.1.100","user_agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36","created_at":"2024-12-22T10:00:00Z","expires_at":"2024-12-22T22:00:00Z","is_active":true}}',
            '{"rate_limit":{"limit":1000,"remaining":847,"reset":1703260800,"retry_after":null},"request_id":"req_xyz789abc123","timestamp":"2024-12-22T16:45:30Z"}',
            '{"webhook":{"id":"wh_123456","event":"payment.completed","data":{"payment_id":"pay_abc123","amount":9999,"currency":"usd","status":"succeeded","customer_id":"cus_xyz789"},"created":1703260800}}',
            '{"oauth":{"access_token":"ya29.a0AfH6SMBx...","token_type":"Bearer","expires_in":3600,"refresh_token":"1//0gYx...","scope":"openid email profile"}}',
            '{"debug":{"request":{"method":"POST","path":"/api/v1/users","headers":{"Content-Type":"application/json","Authorization":"Bearer ***"},"body":{"email":"test@example.com"}},"response":{"status":201,"time_ms":45},"trace_id":"trace_abc123"}}',
            '{"config":{"app":{"name":"Enterprise Portal","version":"3.2.1","environment":"production"},"features":{"dark_mode":true,"beta_features":false,"maintenance_mode":false},"limits":{"max_upload_size":"50MB","rate_limit":"1000/hour"}}}',
            '{"analytics":{"page_views":{"today":12345,"this_week":87654,"this_month":345678},"unique_visitors":{"today":4567,"this_week":23456,"this_month":98765},"bounce_rate":"32.5%","avg_session_duration":"4m 32s"}}',
            '{"search":{"query":"enterprise software","results":[{"id":1,"title":"Enterprise Resource Planning","score":0.95},{"id":2,"title":"Enterprise Security Suite","score":0.87}],"total":156,"took_ms":23,"page":1,"per_page":10}}',
            '{"batch":{"id":"batch_123","status":"completed","total_items":1000,"processed":1000,"failed":3,"started_at":"2024-12-22T10:00:00Z","completed_at":"2024-12-22T10:15:32Z","errors":[{"item_id":45,"error":"Invalid format"},{"item_id":123,"error":"Duplicate entry"}]}}',
            '{"notification":{"id":"notif_abc123","type":"email","recipient":"user@example.com","subject":"Your order has shipped","status":"delivered","sent_at":"2024-12-22T14:30:00Z","opened_at":"2024-12-22T15:45:00Z"}}',
            '{"cache":{"status":"hit","key":"user:12345:profile","ttl":3600,"size_bytes":2048,"created_at":"2024-12-22T10:00:00Z","last_accessed":"2024-12-22T16:30:00Z","hit_count":156}}',
            '{"queue":{"name":"email_notifications","messages":{"pending":234,"processing":12,"completed":45678,"failed":23},"consumers":3,"avg_processing_time_ms":150,"oldest_message_age":"2m 15s"}}',
        ]
        
        # Ëé∑ÂèñÂüüÂêçÁõÆÊ†á
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL LIMIT 80")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        for target_id, target_name in domain_targets:
            num = random.randint(50, 100)
            selected = random.sample(paths, min(num, len(paths)))
            
            for path in selected:
                protocol = random.choice(['https', 'http'])
                port = random.choice([443, 8443, 3000, 8080])
                url = f'{protocol}://{target_name}:{port}{path}' if port != 443 else f'{protocol}://{target_name}{path}'
                
                batch_data.append((
                    url, target_id, target_name, 'API Documentation - Swagger UI',
                    random.choice(['nginx/1.24.0', 'gunicorn/21.2.0']),
                    random.choice([200, 201, 301, 400, 401, 403, 404, 500]),
                    random.randint(100, 50000), 'application/json',
                    random.choice([['Node.js', 'Express'], ['Python', 'FastAPI'], ['Go', 'Gin']]),
                    '', random.choice(body_previews),
                    random.choice([True, False, None]), random.choice(gf_patterns)
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO endpoint (
                    url, target_id, host, title, webserver, status_code, content_length,
                    content_type, tech, location, body_preview, vhost, matched_gf_patterns,
                    created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™Á´ØÁÇπ\n")


    def create_directories(self, target_ids: list, website_ids: list):
        """ÂàõÂª∫ÁõÆÂΩï"""
        print("üìÅ ÂàõÂª∫ÁõÆÂΩï...")
        cur = self.conn.cursor()
        
        if not website_ids:
            print("  ‚ö† Ê≤°ÊúâÁΩëÁ´ôÔºåË∑≥Ëøá\n")
            return
        
        dir_paths = [
            '/admin/', '/administrator/', '/wp-admin/', '/wp-content/', '/backup/', '/backups/',
            '/old/', '/archive/', '/temp/', '/test/', '/dev/', '/staging/', '/config/',
            '/api/', '/api/v1/', '/api/v2/', '/uploads/', '/files/', '/documents/', '/docs/',
            '/images/', '/assets/', '/static/', '/css/', '/js/', '/logs/', '/debug/',
            '/private/', '/secure/', '/internal/', '/data/', '/database/', '/phpmyadmin/',
            '/cgi-bin/', '/includes/', '/lib/', '/vendor/', '/node_modules/', '/plugins/',
            '/themes/', '/templates/', '/src/', '/app/', '/portal/', '/dashboard/', '/panel/',
            '/user/', '/users/', '/account/', '/profile/', '/member/', '/customer/',
            # Êâ©Â±ïÁõÆÂΩï
            '/api/v3/', '/api/internal/', '/api/admin/', '/api/public/', '/api/private/',
            '/admin/config/', '/admin/logs/', '/admin/backup/', '/admin/users/', '/admin/settings/',
            '/system/', '/system/config/', '/system/logs/', '/system/backup/', '/system/cache/',
            '/storage/', '/storage/uploads/', '/storage/temp/', '/storage/cache/', '/storage/logs/',
            '/resources/', '/resources/images/', '/resources/documents/', '/resources/templates/',
            '/public/', '/public/assets/', '/public/uploads/', '/public/images/', '/public/files/',
            '/private/data/', '/private/config/', '/private/keys/', '/private/certificates/',
            '/backup/daily/', '/backup/weekly/', '/backup/monthly/', '/backup/database/',
            '/logs/access/', '/logs/error/', '/logs/audit/', '/logs/security/', '/logs/application/',
            '/cache/', '/cache/views/', '/cache/data/', '/cache/sessions/', '/cache/compiled/',
            '/tmp/', '/tmp/uploads/', '/tmp/sessions/', '/tmp/cache/', '/tmp/exports/',
            '/exports/', '/exports/reports/', '/exports/data/', '/exports/csv/', '/exports/pdf/',
            '/imports/', '/imports/data/', '/imports/csv/', '/imports/xml/', '/imports/json/',
            '/reports/', '/reports/daily/', '/reports/weekly/', '/reports/monthly/', '/reports/annual/',
            '/media/', '/media/images/', '/media/videos/', '/media/audio/', '/media/documents/',
            '/downloads/', '/downloads/software/', '/downloads/documents/', '/downloads/updates/',
        ]
        
        content_types = ['text/html; charset=utf-8', 'application/json', 'text/plain', 'text/css', 
                         'application/xml', 'application/javascript', 'text/xml']
        
        # Ëé∑ÂèñÁΩëÁ´ô‰ø°ÊÅØ(Áî®‰∫éÁîüÊàêÁõÆÂΩï URL)
        cur.execute("SELECT id, url, target_id FROM website LIMIT 100")
        websites = cur.fetchall()
        
        count = 0
        batch_data = []
        for website_id, website_url, target_id in websites:
            num = random.randint(60, 100)
            selected = random.sample(dir_paths, min(num, len(dir_paths)))
            
            for path in selected:
                url = website_url.rstrip('/') + path
                batch_data.append((
                    url, target_id,
                    random.choice([200, 301, 302, 403, 404, 500]),
                    random.randint(0, 100000), random.randint(0, 5000), random.randint(0, 500),
                    random.choice(content_types), random.randint(10000000, 5000000000)
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO directory (
                    url, target_id, status, content_length, words, lines,
                    content_type, duration, created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÁõÆÂΩï\n")

    def create_host_port_mappings(self, target_ids: list):
        """ÂàõÂª∫‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ"""
        print("üîå ÂàõÂª∫‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ...")
        cur = self.conn.cursor()
        
        # Êâ©Â±ïÁ´ØÂè£ÂàóË°®ÔºåÂåÖÂê´Êõ¥Â§öÂ∏∏ËßÅÁ´ØÂè£
        ports = [
            # Â∏∏ËßÅÊúçÂä°Á´ØÂè£
            20, 21, 22, 23, 25, 26, 53, 69, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,
            110, 111, 113, 119, 123, 135, 137, 138, 139, 143, 161, 162, 179, 194, 199,
            389, 443, 444, 445, 465, 500, 512, 513, 514, 515, 520, 523, 524, 548, 554,
            # Êï∞ÊçÆÂ∫ìÁ´ØÂè£
            1433, 1434, 1521, 1522, 1525, 1526, 1527, 1528, 1529, 1530,
            3306, 3307, 3308, 5432, 5433, 5434, 6379, 6380, 6381,
            9200, 9201, 9300, 9301, 27017, 27018, 27019, 28017,
            # Web ÊúçÂä°Á´ØÂè£
            8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010,
            8080, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8088, 8089, 8090,
            8443, 8444, 8445, 8888, 8889, 9000, 9001, 9002, 9003, 9090, 9091, 9443,
            # Ê∂àÊÅØÈòüÂàóÂíåÁºìÂ≠ò
            5672, 5673, 15672, 25672, 4369, 11211, 11212, 11213,
            # ÂÆπÂô®ÂíåÁºñÊéí
            2375, 2376, 2377, 2379, 2380, 6443, 6444, 10250, 10251, 10252, 10255,
            # ÁõëÊéßÂíåÊó•Âøó
            3000, 3001, 3002, 9090, 9091, 9093, 9094, 9100, 9104, 9115, 9116,
            5601, 5602, 9600, 9601, 24224, 24225,
            # ÂÖ∂‰ªñÂ∏∏ËßÅÁ´ØÂè£
            993, 995, 1080, 1081, 1723, 2049, 2181, 2182, 2183, 3128, 3129, 3389, 3390,
            4443, 4444, 5000, 5001, 5002, 5003, 5900, 5901, 5902, 5984, 5985,
            6000, 6001, 6002, 7001, 7002, 7003, 7070, 7071, 7443, 7474, 7687,
            8161, 8162, 8180, 8181, 8200, 8201, 8280, 8281, 8300, 8301, 8400, 8401,
            8500, 8501, 8600, 8601, 8686, 8687, 8787, 8788, 8880, 8881, 8983, 8984,
            9418, 9419, 9999, 10000, 10001, 10002, 11111, 12345, 15000, 15001,
            16379, 16380, 18080, 18081, 19999, 20000, 22222, 27018, 27019, 28015, 28016,
            29015, 29016, 30000, 30001, 31337, 32768, 33060, 33061, 44818, 47001, 49152,
            50000, 50001, 50070, 50075, 50090, 54321, 55555, 60000, 60001, 61616, 61617,
        ]
        # ÂéªÈáç
        ports = list(set(ports))
        
        # Ëé∑ÂèñÂüüÂêçÁõÆÊ†á
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL LIMIT 80")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        for target_id, target_name in domain_targets:
            num_ips = random.randint(15, 30)
            
            for _ in range(num_ips):
                ip = f'192.168.{random.randint(1, 254)}.{random.randint(1, 254)}'
                # Â¢ûÂä†ÊØè‰∏™ IP ÁöÑÁ´ØÂè£Êï∞ÈáèÔºå30-60 ‰∏™Á´ØÂè£
                num_ports = random.randint(30, 60)
                selected_ports = random.sample(ports, min(num_ports, len(ports)))
                
                for port in selected_ports:
                    batch_data.append((target_id, target_name, ip, port))
                    count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO host_port_mapping (target_id, host, ip, port, created_at)
                VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, NOW())")
                    
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ\n")

    def create_vulnerabilities(self, target_ids: list):
        """ÂàõÂª∫ÊºèÊ¥û"""
        print("üêõ ÂàõÂª∫ÊºèÊ¥û...")
        cur = self.conn.cursor()
        
        vuln_types = [
            'sql-injection', 'cross-site-scripting-xss', 'cross-site-request-forgery-csrf',
            'server-side-request-forgery-ssrf', 'xml-external-entity-xxe', 'remote-code-execution-rce',
            'local-file-inclusion-lfi', 'directory-traversal', 'authentication-bypass',
            'insecure-direct-object-reference-idor', 'sensitive-data-exposure', 'security-misconfiguration',
            'broken-access-control', 'cors-misconfiguration', 'subdomain-takeover',
            'exposed-admin-panel', 'default-credentials', 'information-disclosure',
            # Êâ©Â±ïÊºèÊ¥ûÁ±ªÂûã
            'command-injection', 'ldap-injection', 'xpath-injection', 'nosql-injection',
            'template-injection-ssti', 'deserialization-vulnerability', 'jwt-vulnerability',
            'open-redirect', 'http-request-smuggling', 'host-header-injection',
            'clickjacking', 'session-fixation', 'session-hijacking', 'privilege-escalation',
            'path-traversal', 'arbitrary-file-upload', 'arbitrary-file-download',
            'buffer-overflow', 'integer-overflow', 'race-condition', 'time-based-attack',
            'blind-sql-injection', 'stored-xss', 'dom-based-xss', 'reflected-xss',
            'crlf-injection', 'http-response-splitting', 'cache-poisoning', 'dns-rebinding',
            'prototype-pollution', 'mass-assignment', 'graphql-introspection-enabled',
            'api-key-exposure', 'hardcoded-credentials', 'weak-password-policy',
            'missing-rate-limiting', 'missing-security-headers', 'insecure-cookie-configuration',
            'tls-ssl-vulnerability', 'weak-cipher-suite', 'certificate-validation-bypass',
        ]
        
        sources = ['nuclei', 'dalfox', 'sqlmap', 'crlfuzz', 'httpx', 'manual-testing',
                   'burp-suite', 'zap', 'nmap', 'nikto', 'wpscan', 'dirsearch', 'ffuf',
                   'amass', 'subfinder', 'masscan', 'nessus', 'qualys', 'acunetix']
        severities = ['unknown', 'info', 'low', 'medium', 'high', 'critical']
        
        descriptions = [
            'A critical SQL injection vulnerability was discovered in the login form authentication module. An attacker can inject malicious SQL queries through the username parameter to bypass authentication or extract sensitive data from the database. The vulnerability exists due to improper input validation and lack of parameterized queries in the authentication module. This vulnerability affects all database operations including user authentication, session management, and data retrieval. Exploitation could lead to complete database compromise, unauthorized access to all user accounts, and potential data exfiltration. Recommended remediation includes implementing parameterized queries, input validation, and web application firewall rules.',
            'A reflected cross-site scripting (XSS) vulnerability was found in the search functionality of the web application. User input is not properly sanitized before being rendered in the response, allowing attackers to execute arbitrary JavaScript code in the context of the victims browser session, potentially stealing session cookies or performing actions on behalf of the user. This vulnerability can be exploited to hijack user sessions, deface the website, redirect users to malicious sites, or steal sensitive information. The attack vector includes crafted URLs that can be distributed via phishing emails or social engineering. Immediate patching is recommended along with implementation of Content Security Policy headers.',
            'Server-Side Request Forgery (SSRF) vulnerability detected in the URL preview feature of the application. An attacker can manipulate the server to make requests to internal services, potentially accessing sensitive internal resources such as cloud metadata endpoints (169.254.169.254), internal APIs, administrative interfaces, or other services that are not directly accessible from the internet. This vulnerability can be chained with other vulnerabilities to achieve remote code execution or access sensitive cloud credentials. The application should implement strict URL validation, whitelist allowed domains, and block requests to internal IP ranges.',
            'Remote Code Execution (RCE) vulnerability found in the file upload functionality of the content management system. Insufficient validation of uploaded files allows attackers to upload malicious scripts and execute arbitrary code on the server. This could lead to complete server compromise, data exfiltration, cryptocurrency mining, ransomware deployment, or lateral movement within the network infrastructure. The vulnerability bypasses file type validation by manipulating Content-Type headers or using double extensions. Recommended fixes include implementing strict file type validation, storing uploads outside the web root, and using antivirus scanning.',
            'Authentication bypass vulnerability discovered in the password reset mechanism of the user management system. Attackers can reset any users password without proper verification by manipulating the reset token or user identifier in the password reset request. This vulnerability allows unauthorized access to any user account including administrative accounts with elevated privileges. The flaw exists in the token validation logic which does not properly verify token ownership. Organizations should implement secure token generation, add rate limiting, and require additional verification steps for password resets.',
            'Insecure Direct Object Reference (IDOR) vulnerability found in the user profile API endpoints. By manipulating the user ID parameter in API requests, attackers can access, modify, or delete other users data without proper authorization checks. This affects all user-related endpoints including profile information, payment details, personal documents, and account settings. The vulnerability stems from missing access control checks at the API layer. Remediation requires implementing proper authorization checks, using indirect object references, and adding audit logging for sensitive operations.',
        ]
        
        paths = ['/api/v1/users/login', '/api/v2/search', '/admin/dashboard', '/portal/upload', '/graphql', '/oauth/authorize',
                 '/api/v1/users/profile', '/api/v2/orders', '/admin/settings', '/portal/documents', '/webhook/callback',
                 '/api/v3/analytics', '/admin/users/export', '/portal/payments', '/api/internal/debug', '/system/config']
        
        # Ëé∑ÂèñÂüüÂêçÁõÆÊ†á
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL LIMIT 80")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        for target_id, target_name in domain_targets:
            num = random.randint(30, 80)
            
            for _ in range(num):
                severity = random.choice(severities)
                cvss_ranges = {
                    'critical': (9.0, 10.0), 'high': (7.0, 8.9), 'medium': (4.0, 6.9),
                    'low': (0.1, 3.9), 'info': (0.0, 0.0), 'unknown': (0.0, 10.0)
                }
                cvss_range = cvss_ranges.get(severity, (0.0, 10.0))
                cvss_score = round(random.uniform(*cvss_range), 1)
                
                path = random.choice(paths)
                url = f'https://{target_name}{path}?param=test&id={random.randint(1, 1000)}'
                
                raw_output = json.dumps({
                    'template': f'CVE-2024-{random.randint(10000, 99999)}',
                    'matcher_name': 'default',
                    'severity': severity,
                    'host': target_name,
                    'matched_at': url,
                })
                
                batch_data.append((
                    target_id, url, random.choice(vuln_types), severity,
                    random.choice(sources), cvss_score, random.choice(descriptions), raw_output
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO vulnerability (
                    target_id, url, vuln_type, severity, source, cvss_score,
                    description, raw_output, created_at
                ) VALUES %s
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÊºèÊ¥û\n")

    def create_subdomain_snapshots(self, scan_ids: list):
        """ÂàõÂª∫Â≠êÂüüÂêçÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫Â≠êÂüüÂêçÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        prefixes = [
            'api', 'admin', 'portal', 'dashboard', 'app', 'mobile', 'staging', 'dev',
            'test', 'qa', 'uat', 'beta', 'mail', 'vpn', 'cdn', 'static',
            'auth', 'login', 'sso', 'oauth', 'identity', 'accounts', 'secure',
            'monitoring', 'metrics', 'grafana', 'prometheus', 'kibana', 'logs',
            'jenkins', 'ci', 'cd', 'gitlab', 'jira', 'confluence', 'kubernetes',
            'www', 'www2', 'ns1', 'ns2', 'mx', 'mx1', 'autodiscover', 'webmail',
        ]
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:  # ‰∏∫Ââç100‰∏™Êâ´ÊèèÂàõÂª∫Âø´ÁÖß
            # Ëé∑ÂèñÊâ´ÊèèÂØπÂ∫îÁöÑÁõÆÊ†áÂüüÂêç
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            num = random.randint(40, 80)
            selected = random.sample(prefixes, min(num, len(prefixes)))
            
            for prefix in selected:
                subdomain_name = f'{prefix}.{target_name}'
                batch_data.append((scan_id, subdomain_name))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO subdomain_snapshot (scan_id, name, created_at)
                VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™Â≠êÂüüÂêçÂø´ÁÖß\n")

    def create_website_snapshots(self, scan_ids: list):
        """ÂàõÂª∫ÁΩëÁ´ôÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫ÁΩëÁ´ôÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        titles = [
            'Enterprise Portal - Login | Secure Access Required - Multi-Factor Authentication',
            'Admin Dashboard - System Management | Configuration Settings Overview',
            'API Documentation - Swagger UI | RESTful Endpoints Reference Guide',
            'Customer Portal - Account Management | Billing Subscription Services',
            'Developer Console - Application Management | API Keys Webhooks Configuration',
            'Support Center - Help Desk | Knowledge Base FAQ Ticket System',
            'Analytics Dashboard - Business Intelligence | Real-time Metrics Reporting',
            'Security Center - Threat Detection | Vulnerability Assessment Reports',
            'User Management - Identity Access Control | Role Permission Administration',
            'Content Management System - Publishing Platform | Media Library Editor',
        ]
        webservers = ['nginx/1.24.0', 'nginx/1.25.3', 'Apache/2.4.57', 'Apache/2.4.58', 
                      'cloudflare', 'gunicorn/21.2.0', 'Microsoft-IIS/10.0']
        tech_stacks = [['React', 'Node.js', 'Express'], ['Vue.js', 'Django', 'PostgreSQL'], 
                       ['Angular', 'Spring Boot', 'MySQL'], ['Next.js', 'FastAPI', 'Redis'],
                       ['Svelte', 'Go', 'MongoDB'], ['React', 'NestJS', 'TypeORM']]
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            for i in range(random.randint(15, 30)):
                protocol = random.choice(['https', 'http'])
                port = random.choice([80, 443, 8080])
                url = f'{protocol}://{target_name}:{port}/' if port not in [80, 443] else f'{protocol}://{target_name}/'
                
                batch_data.append((
                    scan_id, url, target_name, random.choice(titles),
                    random.choice(webservers), random.choice(tech_stacks),
                    random.choice([200, 301, 403]),
                    random.randint(1000, 50000), 'text/html; charset=utf-8',
                    '',  # location Â≠óÊÆµ
                    '<!DOCTYPE html><html><head><title>Test</title></head><body>Content</body></html>'
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO website_snapshot (
                    scan_id, url, host, title, web_server, tech, status,
                    content_length, content_type, location, body_preview, created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÁΩëÁ´ôÂø´ÁÖß\n")

    def create_endpoint_snapshots(self, scan_ids: list):
        """ÂàõÂª∫Á´ØÁÇπÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫Á´ØÁÇπÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        paths = [
            '/api/v1/users', '/api/v1/auth/login', '/api/v2/products',
            '/admin/dashboard', '/graphql', '/health', '/metrics',
            '/api/v1/organizations/departments/teams/members',
            '/api/v2/inventory/warehouse/locations/products',
            '/api/v3/reporting/analytics/metrics/summary',
            '/admin/system/configuration/security/settings',
            '/portal/customer/account/billing/invoices',
            '/internal/monitoring/kubernetes/pods/status',
            '/webhook/integration/payment/callback/handler',
            '/oauth/authorize/callback/redirect',
            '/swagger/v1/api-docs/openapi.json',
        ]
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            for path in random.sample(paths, min(random.randint(20, 40), len(paths))):
                url = f'https://{target_name}{path}'
                batch_data.append((
                    scan_id, url, target_name, 'API Endpoint',
                    random.choice([200, 201, 401, 403, 404]),
                    random.randint(100, 5000),
                    '',  # location
                    'nginx/1.24.0',
                    'application/json', ['REST', 'JSON'],
                    '{"status":"ok","data":{}}',
                    []  # matched_gf_patterns
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO endpoint_snapshot (
                    scan_id, url, host, title, status_code, content_length,
                    location, webserver, content_type, tech, body_preview,
                    matched_gf_patterns, created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™Á´ØÁÇπÂø´ÁÖß\n")

    def create_directory_snapshots(self, scan_ids: list):
        """ÂàõÂª∫ÁõÆÂΩïÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫ÁõÆÂΩïÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        dirs = [
            '/admin/', '/backup/', '/config/', '/uploads/', '/static/',
            '/assets/', '/images/', '/js/', '/css/', '/api/',
            '/admin/config/', '/admin/logs/', '/admin/backup/', '/admin/users/',
            '/system/', '/system/config/', '/system/logs/', '/system/cache/',
            '/storage/', '/storage/uploads/', '/storage/temp/', '/storage/cache/',
            '/resources/', '/resources/images/', '/resources/documents/',
            '/public/', '/public/assets/', '/public/uploads/', '/public/images/',
            '/private/data/', '/private/config/', '/private/keys/',
            '/backup/daily/', '/backup/weekly/', '/backup/database/',
            '/logs/access/', '/logs/error/', '/logs/audit/', '/logs/security/',
            '/cache/', '/cache/views/', '/cache/data/', '/cache/sessions/',
            '/tmp/', '/tmp/uploads/', '/tmp/sessions/', '/tmp/exports/',
            '/exports/', '/exports/reports/', '/exports/data/', '/exports/csv/',
        ]
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            for d in random.sample(dirs, min(random.randint(30, 50), len(dirs))):
                url = f'https://{target_name}{d}'
                batch_data.append((
                    scan_id, url, random.choice([200, 301, 403]),
                    random.randint(500, 10000), random.randint(50, 500),
                    random.randint(10, 100), 'text/html',
                    random.randint(10000000, 500000000)  # Á∫≥Áßí
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO directory_snapshot (
                    scan_id, url, status, content_length, words, lines,
                    content_type, duration, created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÁõÆÂΩïÂø´ÁÖß\n")

    def create_host_port_mapping_snapshots(self, scan_ids: list):
        """ÂàõÂª∫‰∏ªÊú∫Á´ØÂè£Êò†Â∞ÑÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫‰∏ªÊú∫Á´ØÂè£Êò†Â∞ÑÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        common_ports = [22, 80, 443, 3306, 5432, 6379, 8080, 8443, 9000,
                        21, 23, 25, 53, 110, 143, 389, 445, 993, 995,
                        1433, 1521, 2049, 2181, 3000, 3389, 5000, 5672,
                        6443, 7001, 8000, 8081, 8888, 9090, 9200, 27017]
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            # ÁîüÊàêÂ§ö‰∏™ÈöèÊú∫ IP
            for _ in range(random.randint(8, 15)):
                ip = f'192.168.{random.randint(1, 254)}.{random.randint(1, 254)}'
                
                for port in random.sample(common_ports, min(random.randint(15, 30), len(common_ports))):
                    batch_data.append((scan_id, target_name, ip, port))
                    count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO host_port_mapping_snapshot (
                    scan_id, host, ip, port, created_at
                ) VALUES %s
                ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™‰∏ªÊú∫Á´ØÂè£Êò†Â∞ÑÂø´ÁÖß\n")

    def create_vulnerability_snapshots(self, scan_ids: list):
        """ÂàõÂª∫ÊºèÊ¥ûÂø´ÁÖß"""
        print("üì∏ ÂàõÂª∫ÊºèÊ¥ûÂø´ÁÖß...")
        cur = self.conn.cursor()
        
        if not scan_ids:
            print("  ‚ö† Áº∫Â∞ëÊâ´Êèè‰ªªÂä°ÔºåË∑≥Ëøá\n")
            return
        
        vuln_types = ['xss', 'sqli', 'ssrf', 'lfi', 'rce', 'xxe', 'csrf',
                      'idor', 'auth-bypass', 'info-disclosure', 'cors-misconfig',
                      'open-redirect', 'command-injection', 'deserialization',
                      'jwt-vulnerability', 'path-traversal', 'file-upload']
        severities = ['critical', 'high', 'medium', 'low', 'info']
        sources = ['nuclei', 'dalfox', 'sqlmap', 'burp-suite', 'zap', 'nmap', 'nikto']
        
        count = 0
        batch_data = []
        for scan_id in scan_ids[:100]:
            cur.execute("""
                SELECT t.name FROM scan s 
                JOIN target t ON s.target_id = t.id 
                WHERE s.id = %s AND t.type = 'domain'
            """, (scan_id,))
            row = cur.fetchone()
            if not row:
                continue
            target_name = row[0]
            
            for _ in range(random.randint(15, 40)):
                severity = random.choice(severities)
                cvss_ranges = {
                    'critical': (9.0, 10.0), 'high': (7.0, 8.9), 'medium': (4.0, 6.9),
                    'low': (0.1, 3.9), 'info': (0.0, 0.0)
                }
                cvss_range = cvss_ranges.get(severity, (0.0, 10.0))
                cvss_score = round(random.uniform(*cvss_range), 1)
                
                url = f'https://{target_name}/api/v1/users?id={random.randint(1, 100)}'
                
                batch_data.append((
                    scan_id, url, random.choice(vuln_types), severity,
                    random.choice(sources), cvss_score,
                    f'Detected {severity} severity vulnerability',
                    json.dumps({'template': f'CVE-2024-{random.randint(10000, 99999)}'})
                ))
                count += 1
        
        # ÊâπÈáèÊèíÂÖ•
        if batch_data:
            execute_values(cur, """
                INSERT INTO vulnerability_snapshot (
                    scan_id, url, vuln_type, severity, source, cvss_score,
                    description, raw_output, created_at
                ) VALUES %s
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count} ‰∏™ÊºèÊ¥ûÂø´ÁÖß\n")


class MillionDataGenerator:
    """
    Áôæ‰∏áÁ∫ßÊï∞ÊçÆÁîüÊàêÂô® - Áî®‰∫éÊµãËØï Dashboard Âç°ÁâáÊ∫¢Âá∫
    
    ÁîüÊàêÊï∞ÊçÆÈáèÔºö
    - Â≠êÂüüÂêç: 200,000
    - ÁΩëÁ´ô: 200,000
    - Á´ØÁÇπ: 200,000
    - IP (host_port_mapping): 200,000
    - ÊºèÊ¥û: 200,000 (critical: 50k, high: 50k, medium: 50k, low: 30k, info: 20k)
    - ÁõÆÊ†á: 1,000
    - ÂéÜÂè≤ÁªüËÆ°: 7Â§©
    """
    
    def __init__(self, clear: bool = False):
        self.conn = psycopg2.connect(**DB_CONFIG)
        self.conn.autocommit = False
        self.clear = clear
        
    def run(self):
        try:
            if self.clear:
                print("üóëÔ∏è  Ê∏ÖÈô§Áé∞ÊúâÊï∞ÊçÆ...")
                self.clear_data()
                
            print("üöÄ ÂºÄÂßãÁîüÊàêÁôæ‰∏áÁ∫ßÊµãËØïÊï∞ÊçÆ(Áî®‰∫é Dashboard Ê∫¢Âá∫ÊµãËØï)...\n")
            
            target_ids = self.create_targets()
            self.create_subdomains(target_ids)
            self.create_websites(target_ids)
            self.create_endpoints(target_ids)
            self.create_host_port_mappings(target_ids)
            self.create_vulnerabilities(target_ids)
            self.create_statistics_history()  # ÁîüÊàêË∂ãÂäøÂõæÊï∞ÊçÆ
            self.update_asset_statistics()
            
            self.conn.commit()
            print("\n‚úÖ Áôæ‰∏áÁ∫ßÊµãËØïÊï∞ÊçÆÁîüÊàêÂÆåÊàêÔºÅ")
            print("üìä ËØ∑Âà∑Êñ∞ Dashboard È°µÈù¢Êü•ÁúãÊïàÊûú")
        except Exception as e:
            self.conn.rollback()
            print(f"\n‚ùå ÁîüÊàêÂ§±Ë¥•: {e}")
            raise
        finally:
            self.conn.close()

    def clear_data(self):
        """Ê∏ÖÈô§ÊâÄÊúâÊµãËØïÊï∞ÊçÆ"""
        cur = self.conn.cursor()
        tables = [
            'vulnerability_snapshot', 'host_port_mapping_snapshot', 'directory_snapshot',
            'endpoint_snapshot', 'website_snapshot', 'subdomain_snapshot',
            'vulnerability', 'host_port_mapping', 'directory', 'endpoint',
            'website', 'subdomain', 'scheduled_scan', 'scan',
            'organization_targets', 'target', 'organization',
            'statistics_history', 'asset_statistics',
        ]
        for table in tables:
            try:
                cur.execute(f"DELETE FROM {table}")
            except Exception:
                pass  # Ë°®ÂèØËÉΩ‰∏çÂ≠òÂú®
        self.conn.commit()
        print("  ‚úì Êï∞ÊçÆÊ∏ÖÈô§ÂÆåÊàê\n")

    def create_targets(self) -> list:
        """ÂàõÂª∫ 1000 ‰∏™Êâ´ÊèèÁõÆÊ†á"""
        print("üéØ ÂàõÂª∫Êâ´ÊèèÁõÆÊ†á (1,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        suffix = random.randint(1000, 9999)
        domains = [
            'example', 'test', 'demo', 'staging', 'production', 'api', 'app', 'web',
            'portal', 'admin', 'dashboard', 'service', 'platform', 'cloud', 'data',
            'analytics', 'security', 'enterprise', 'global', 'internal', 'external'
        ]
        tlds = ['.com', '.io', '.net', '.org', '.dev', '.app', '.cloud', '.tech']
        
        ids = []
        for i in range(1000):
            domain = f'{random.choice(domains)}-{suffix}-{i:04d}{random.choice(tlds)}'
            cur.execute("""
                INSERT INTO target (name, type, created_at, deleted_at)
                VALUES (%s, 'domain', NOW() - INTERVAL '%s days', NULL)
                ON CONFLICT DO NOTHING
                RETURNING id
            """, (domain, random.randint(0, 365)))
            row = cur.fetchone()
            if row:
                ids.append(row[0])
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {len(ids)} ‰∏™Êâ´ÊèèÁõÆÊ†á\n")
        return ids

    def create_subdomains(self, target_ids: list):
        """ÂàõÂª∫ 200,000 ‰∏™Â≠êÂüüÂêç"""
        print("üåê ÂàõÂª∫Â≠êÂüüÂêç (200,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        prefixes = [
            'api', 'admin', 'portal', 'dashboard', 'app', 'mobile', 'staging', 'dev',
            'test', 'qa', 'uat', 'beta', 'alpha', 'demo', 'sandbox', 'internal',
            'secure', 'auth', 'login', 'sso', 'oauth', 'identity', 'accounts',
            'mail', 'smtp', 'imap', 'webmail', 'ftp', 'sftp', 'files', 'storage',
            'cdn', 'static', 'assets', 'media', 'db', 'database', 'mysql', 'postgres',
            'redis', 'mongo', 'elastic', 'vpn', 'remote', 'gateway', 'proxy',
            'monitoring', 'metrics', 'grafana', 'prometheus', 'kibana', 'logs',
            'jenkins', 'ci', 'cd', 'gitlab', 'jira', 'confluence', 'kubernetes', 'k8s',
            'www', 'www2', 'www3', 'ns1', 'ns2', 'mx', 'mx1', 'mx2', 'autodiscover',
        ]
        secondary = ['', 'prod-', 'dev-', 'staging-', 'test-', 'us-', 'eu-', 'ap-']
        
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        batch_size = 50000  # Â¢ûÂä†ÊâπÈáèÂ§ßÂ∞è
        target_count = 200000
        per_target = target_count // len(domain_targets) + 1
        
        for target_id, target_name in domain_targets:
            for i in range(per_target):
                if count >= target_count:
                    break
                prefix = random.choice(prefixes)
                sec = random.choice(secondary)
                subdomain_name = f'{sec}{prefix}-{i:04d}.{target_name}'
                batch_data.append((subdomain_name, target_id, random.randint(0, 90)))
                count += 1
                
                if len(batch_data) >= batch_size:
                    execute_values(cur, """
                        INSERT INTO subdomain (name, target_id, created_at)
                        VALUES %s ON CONFLICT DO NOTHING
                    """, batch_data, template="(%s, %s, NOW() - INTERVAL '%s days')")
                    self.conn.commit()  # ÊØèÊâπÊ¨°Êèê‰∫§
                    batch_data = []
                    print(f"    ‚úì {count:,} / {target_count:,}")
            if count >= target_count:
                break
        
        if batch_data:
            execute_values(cur, """
                INSERT INTO subdomain (name, target_id, created_at)
                VALUES %s ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, NOW() - INTERVAL '%s days')")
            self.conn.commit()
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count:,} ‰∏™Â≠êÂüüÂêç\n")

    def create_websites(self, target_ids: list):
        """ÂàõÂª∫ 200,000 ‰∏™ÁΩëÁ´ô"""
        print("üåç ÂàõÂª∫ÁΩëÁ´ô (200,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        batch_size = 50000  # Â¢ûÂä†ÊâπÈáèÂ§ßÂ∞è
        target_count = 200000
        per_target = target_count // len(domain_targets) + 1
        
        for target_id, target_name in domain_targets:
            for i in range(per_target):
                if count >= target_count:
                    break
                protocol = random.choice(['https', 'http'])
                port = random.choice([80, 443, 8080, 8443, 3000])
                url = f'{protocol}://{target_name}:{port}/path-{i:04d}/'
                
                batch_data.append((
                    url, target_id, target_name, f'Website Title {count}',
                    'nginx/1.24.0', ['React', 'Node.js'],
                    random.choice([200, 301, 403]), random.randint(1000, 50000),
                    'text/html', '', '<!DOCTYPE html><html></html>'
                ))
                count += 1
                
                if len(batch_data) >= batch_size:
                    execute_values(cur, """
                        INSERT INTO website (url, target_id, host, title, webserver, tech, 
                            status_code, content_length, content_type, location, body_preview, created_at)
                        VALUES %s ON CONFLICT DO NOTHING
                    """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                    self.conn.commit()
                    batch_data = []
                    print(f"    ‚úì {count:,} / {target_count:,}")
            if count >= target_count:
                break
        
        if batch_data:
            execute_values(cur, """
                INSERT INTO website (url, target_id, host, title, webserver, tech, 
                    status_code, content_length, content_type, location, body_preview, created_at)
                VALUES %s ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
            self.conn.commit()
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count:,} ‰∏™ÁΩëÁ´ô\n")

    def create_endpoints(self, target_ids: list):
        """ÂàõÂª∫ 200,000 ‰∏™Á´ØÁÇπ"""
        print("üîó ÂàõÂª∫Á´ØÁÇπ (200,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        paths = ['/api/v1/', '/api/v2/', '/admin/', '/portal/', '/graphql/', '/health/', '/metrics/']
        
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        batch_size = 50000  # Â¢ûÂä†ÊâπÈáèÂ§ßÂ∞è
        target_count = 200000
        per_target = target_count // len(domain_targets) + 1
        
        for target_id, target_name in domain_targets:
            for i in range(per_target):
                if count >= target_count:
                    break
                path = random.choice(paths)
                url = f'https://{target_name}{path}endpoint-{i:04d}'
                
                batch_data.append((
                    url, target_id, target_name, 'API Endpoint',
                    'nginx/1.24.0', random.choice([200, 201, 401, 403]),
                    random.randint(100, 5000), 'application/json',
                    ['Node.js', 'Express'], '', '{"status":"ok"}', None, []
                ))
                count += 1
                
                if len(batch_data) >= batch_size:
                    execute_values(cur, """
                        INSERT INTO endpoint (url, target_id, host, title, webserver, status_code,
                            content_length, content_type, tech, location, body_preview, vhost, 
                            matched_gf_patterns, created_at)
                        VALUES %s ON CONFLICT DO NOTHING
                    """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                    self.conn.commit()
                    batch_data = []
                    print(f"    ‚úì {count:,} / {target_count:,}")
            if count >= target_count:
                break
        
        if batch_data:
            execute_values(cur, """
                INSERT INTO endpoint (url, target_id, host, title, webserver, status_code,
                    content_length, content_type, tech, location, body_preview, vhost, 
                    matched_gf_patterns, created_at)
                VALUES %s ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())")
            self.conn.commit()
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count:,} ‰∏™Á´ØÁÇπ\n")

    def create_host_port_mappings(self, target_ids: list):
        """ÂàõÂª∫ 200,000 ‰∏™‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ(Áî®‰∫é IP ÁªüËÆ°)"""
        print("üîå ÂàõÂª∫‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ (200,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        ports = [22, 80, 443, 3306, 5432, 6379, 8080, 8443, 9000, 9200, 27017]
        
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        batch_size = 50000  # Â¢ûÂä†ÊâπÈáèÂ§ßÂ∞è
        target_count = 200000
        per_target = target_count // len(domain_targets) + 1
        
        for target_id, target_name in domain_targets:
            for i in range(per_target):
                if count >= target_count:
                    break
                ip = f'192.168.{random.randint(1, 254)}.{random.randint(1, 254)}'
                port = random.choice(ports)
                
                batch_data.append((target_id, target_name, ip, port))
                count += 1
                
                if len(batch_data) >= batch_size:
                    execute_values(cur, """
                        INSERT INTO host_port_mapping (target_id, host, ip, port, created_at)
                        VALUES %s ON CONFLICT DO NOTHING
                    """, batch_data, template="(%s, %s, %s, %s, NOW())")
                    self.conn.commit()
                    batch_data = []
                    print(f"    ‚úì {count:,} / {target_count:,}")
            if count >= target_count:
                break
        
        if batch_data:
            execute_values(cur, """
                INSERT INTO host_port_mapping (target_id, host, ip, port, created_at)
                VALUES %s ON CONFLICT DO NOTHING
            """, batch_data, template="(%s, %s, %s, %s, NOW())")
            self.conn.commit()
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count:,} ‰∏™‰∏ªÊú∫Á´ØÂè£Êò†Â∞Ñ\n")

    def create_vulnerabilities(self, target_ids: list):
        """ÂàõÂª∫ 200,000 ‰∏™ÊºèÊ¥û (critical: 50k, high: 50k, medium: 50k, low: 30k, info: 20k)"""
        print("üêõ ÂàõÂª∫ÊºèÊ¥û (200,000 ‰∏™)...")
        cur = self.conn.cursor()
        
        vuln_types = ['sql-injection', 'xss', 'ssrf', 'rce', 'lfi', 'xxe', 'csrf', 'idor']
        sources = ['nuclei', 'dalfox', 'sqlmap', 'burp-suite', 'zap']
        
        # Êåâ‰∏•ÈáçÁ®ãÂ∫¶ÂàÜÈÖçÊï∞Èáè
        severity_counts = {
            'critical': 50000,
            'high': 50000,
            'medium': 50000,
            'low': 30000,
            'info': 20000,
        }
        
        cur.execute("SELECT id, name FROM target WHERE type = 'domain' AND deleted_at IS NULL")
        domain_targets = cur.fetchall()
        
        count = 0
        batch_data = []
        batch_size = 50000  # Â¢ûÂä†ÊâπÈáèÂ§ßÂ∞è
        
        for severity, target_count in severity_counts.items():
            print(f"    ÂàõÂª∫ {severity} Á∫ßÂà´ÊºèÊ¥û: {target_count:,} ‰∏™")
            cvss_ranges = {
                'critical': (9.0, 10.0), 'high': (7.0, 8.9), 'medium': (4.0, 6.9),
                'low': (0.1, 3.9), 'info': (0.0, 0.0)
            }
            cvss_range = cvss_ranges.get(severity, (0.0, 10.0))
            
            severity_count = 0
            per_target = target_count // len(domain_targets) + 1
            
            for target_id, target_name in domain_targets:
                for i in range(per_target):
                    if severity_count >= target_count:
                        break
                    
                    cvss_score = round(random.uniform(*cvss_range), 1)
                    url = f'https://{target_name}/api/v1/vuln-{severity_count:06d}'
                    
                    batch_data.append((
                        target_id, url, random.choice(vuln_types), severity,
                        random.choice(sources), cvss_score,
                        f'{severity.upper()} vulnerability detected',
                        json.dumps({'template': f'CVE-2024-{random.randint(10000, 99999)}'})
                    ))
                    severity_count += 1
                    count += 1
                    
                    if len(batch_data) >= batch_size:
                        execute_values(cur, """
                            INSERT INTO vulnerability (target_id, url, vuln_type, severity, source,
                                cvss_score, description, raw_output, created_at)
                            VALUES %s
                        """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
                        self.conn.commit()
                        batch_data = []
                        print(f"      ‚úì {severity_count:,} / {target_count:,}")
                if severity_count >= target_count:
                    break
        
        if batch_data:
            execute_values(cur, """
                INSERT INTO vulnerability (target_id, url, vuln_type, severity, source,
                    cvss_score, description, raw_output, created_at)
                VALUES %s
            """, batch_data, template="(%s, %s, %s, %s, %s, %s, %s, %s, NOW())")
            self.conn.commit()
                
        print(f"  ‚úì ÂàõÂª∫‰∫Ü {count:,} ‰∏™ÊºèÊ¥û\n")

    def create_statistics_history(self):
        """ÂàõÂª∫ 7 Â§©ÁöÑÁªüËÆ°ÂéÜÂè≤Êï∞ÊçÆ(Áî®‰∫éË∂ãÂäøÂõæ)"""
        print("üìà ÂàõÂª∫ÁªüËÆ°ÂéÜÂè≤Êï∞ÊçÆ (7 Â§©)...")
        cur = self.conn.cursor()
        
        # ÂÖàÊ∏ÖÈô§ÊóßÁöÑÂéÜÂè≤Êï∞ÊçÆ
        cur.execute("DELETE FROM statistics_history")
        
        # ÁîüÊàê 7 Â§©ÁöÑÂéÜÂè≤Êï∞ÊçÆÔºåÊï∞ÂÄºÈÄêÊ∏êÂ¢ûÈïø
        base_values = {
            'total_targets': 800,
            'total_subdomains': 150000,
            'total_ips': 150000,
            'total_endpoints': 150000,
            'total_websites': 150000,
            'total_vulns': 150000,
        }
        
        for i in range(7):
            date = datetime.now().date() - timedelta(days=6-i)
            growth_factor = 1 + (i * 0.05)  # ÊØèÂ§©Â¢ûÈïø 5%
            
            total_targets = int(base_values['total_targets'] * growth_factor)
            total_subdomains = int(base_values['total_subdomains'] * growth_factor)
            total_ips = int(base_values['total_ips'] * growth_factor)
            total_endpoints = int(base_values['total_endpoints'] * growth_factor)
            total_websites = int(base_values['total_websites'] * growth_factor)
            total_vulns = int(base_values['total_vulns'] * growth_factor)
            total_assets = total_subdomains + total_ips + total_endpoints + total_websites
            
            cur.execute("""
                INSERT INTO statistics_history (
                    date, total_targets, total_subdomains, total_ips, total_endpoints,
                    total_websites, total_vulns, total_assets, created_at, updated_at
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                ON CONFLICT (date) DO UPDATE SET
                    total_targets = EXCLUDED.total_targets,
                    total_subdomains = EXCLUDED.total_subdomains,
                    total_ips = EXCLUDED.total_ips,
                    total_endpoints = EXCLUDED.total_endpoints,
                    total_websites = EXCLUDED.total_websites,
                    total_vulns = EXCLUDED.total_vulns,
                    total_assets = EXCLUDED.total_assets,
                    updated_at = NOW()
            """, (date, total_targets, total_subdomains, total_ips, total_endpoints,
                  total_websites, total_vulns, total_assets))
        
        print(f"  ‚úì ÂàõÂª∫‰∫Ü 7 Â§©ÁöÑÁªüËÆ°ÂéÜÂè≤Êï∞ÊçÆ\n")

    def update_asset_statistics(self):
        """Êõ¥Êñ∞ËµÑ‰∫ßÁªüËÆ°Ë°®(Dashboard Âç°Áâá‰ΩøÁî®)"""
        print("üìä Êõ¥Êñ∞ËµÑ‰∫ßÁªüËÆ°Ë°®...")
        cur = self.conn.cursor()
        
        # ÁªüËÆ°ÂÆûÈôÖÊï∞ÊçÆ
        cur.execute("SELECT COUNT(*) FROM target WHERE deleted_at IS NULL")
        total_targets = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM subdomain")
        total_subdomains = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(DISTINCT ip) FROM host_port_mapping")
        total_ips = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM endpoint")
        total_endpoints = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM website")
        total_websites = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM vulnerability")
        total_vulns = cur.fetchone()[0]
        
        total_assets = total_subdomains + total_ips + total_endpoints + total_websites
        
        # Êõ¥Êñ∞ÊàñÊèíÂÖ•ÁªüËÆ°Êï∞ÊçÆ
        cur.execute("""
            INSERT INTO asset_statistics (
                id, total_targets, total_subdomains, total_ips, total_endpoints,
                total_websites, total_vulns, total_assets,
                prev_targets, prev_subdomains, prev_ips, prev_endpoints,
                prev_websites, prev_vulns, prev_assets,
                updated_at
            ) VALUES (
                1, %s, %s, %s, %s, %s, %s, %s,
                %s, %s, %s, %s, %s, %s, %s, NOW()
            )
            ON CONFLICT (id) DO UPDATE SET
                total_targets = EXCLUDED.total_targets,
                total_subdomains = EXCLUDED.total_subdomains,
                total_ips = EXCLUDED.total_ips,
                total_endpoints = EXCLUDED.total_endpoints,
                total_websites = EXCLUDED.total_websites,
                total_vulns = EXCLUDED.total_vulns,
                total_assets = EXCLUDED.total_assets,
                prev_targets = asset_statistics.total_targets,
                prev_subdomains = asset_statistics.total_subdomains,
                prev_ips = asset_statistics.total_ips,
                prev_endpoints = asset_statistics.total_endpoints,
                prev_websites = asset_statistics.total_websites,
                prev_vulns = asset_statistics.total_vulns,
                prev_assets = asset_statistics.total_assets,
                updated_at = NOW()
        """, (total_targets, total_subdomains, total_ips, total_endpoints,
              total_websites, total_vulns, total_assets,
              int(total_targets * 0.9), int(total_subdomains * 0.9), int(total_ips * 0.9),
              int(total_endpoints * 0.9), int(total_websites * 0.9), int(total_vulns * 0.9),
              int(total_assets * 0.9)))
        
        print(f"  ‚úì ÁªüËÆ°Êï∞ÊçÆÂ∑≤Êõ¥Êñ∞:")
        print(f"    - ÁõÆÊ†á: {total_targets:,}")
        print(f"    - Â≠êÂüüÂêç: {total_subdomains:,}")
        print(f"    - IP: {total_ips:,}")
        print(f"    - Á´ØÁÇπ: {total_endpoints:,}")
        print(f"    - ÁΩëÁ´ô: {total_websites:,}")
        print(f"    - ÊºèÊ¥û: {total_vulns:,}")
        print(f"    - ÊÄªËµÑ‰∫ß: {total_assets:,}\n")


def main():
    parser = argparse.ArgumentParser(description="Áõ¥Êé•ÈÄöËøá SQL ÁîüÊàêÊµãËØïÊï∞ÊçÆ")
    parser.add_argument('--clear', action='store_true', help='Ê∏ÖÈô§Áé∞ÊúâÊï∞ÊçÆÂêéÈáçÊñ∞ÁîüÊàê')
    parser.add_argument('--million', action='store_true', help='ÁîüÊàêÁôæ‰∏áÁ∫ßÊï∞ÊçÆ(Áî®‰∫é Dashboard Ê∫¢Âá∫ÊµãËØï)')
    args = parser.parse_args()
    
    if args.million:
        generator = MillionDataGenerator(clear=args.clear)
    else:
        generator = TestDataGenerator(clear=args.clear)
    generator.run()


if __name__ == "__main__":
    main()
